{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# Credit for some parts to: https://www.kaggle.com/kyakovlev/preprocessing-bert-public\n",
    "# Number extraction and hashtags is my baby\n",
    "\n",
    "# General imports|  \n",
    "import pandas as pd\n",
    "import re, warnings, pickle, itertools, emoji, unicodedata\n",
    "\n",
    "# custom imports\n",
    "from gensim.utils import deaccent\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from utils.datasets import *\n",
    "from pandarallel import pandarallel\n",
    "import fasttext\n",
    "\n",
    "pandarallel.initialize()\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.max_colwidth = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "## Initial vars\n",
    "\n",
    "HELPER_PATH             = '../../data/helpers/'\n",
    "LOCAL_TEST = True       ## Local test - for test performance on part of the train set only\n",
    "verbose = True\n",
    "WPLACEHOLDER = 'word_placeholder'\n",
    "URL_TAG = '@URL'\n",
    "USER_TAG = '@USR'\n",
    "NUMBER_TAG = '@NUM'\n",
    "HASH_TAG = '@HTAG'\n",
    "CURRENCY_TAG = '@CURR'\n",
    "IMMUTABLES = [WPLACEHOLDER, URL_TAG, USER_TAG, NUMBER_TAG, HASH_TAG, CURRENCY_TAG]\n",
    "\n",
    "SEED = 42               ## Seed for enviroment\n",
    "seed_everything(SEED)   ## Seed everything"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "## Preprocess helpers\n",
    "def place_hold(w, tag=WPLACEHOLDER):\n",
    "    return tag + '[' + re.sub(' ', '___', w) + ']'\n",
    "\n",
    "## Helpers\n",
    "def check_replace(w):\n",
    "    return not bool(re.search('|'.join(IMMUTABLES), w))\n",
    "\n",
    "def make_cleaning(s, c_dict):\n",
    "    if check_replace(s):\n",
    "        s = s.translate(c_dict)\n",
    "    return s\n",
    "\n",
    "def make_dict_cleaning(s, w_dict, skip_check=False):\n",
    "    # Replaces a word using dict if it is mutable\n",
    "    if skip_check or check_replace(s):\n",
    "        s = w_dict.get(s, s)\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "## Get basic helper data\n",
    "\n",
    "bert_uncased_vocabulary = load_helper_file('helper_bert_uncased_vocabulary')\n",
    "bert_cased_vocabulary   = load_helper_file('helper_bert_cased_vocabulary')\n",
    "bert_char_list          = list(set([c for line in bert_uncased_vocabulary+bert_cased_vocabulary for c in line]))\n",
    "\n",
    "url_extensions          = load_helper_file('helper_url_extensions')\n",
    "html_tags               = load_helper_file('helper_html_tags')\n",
    "good_chars_dieter       = load_helper_file('helper_good_chars_dieter')\n",
    "bad_chars_dieter        = load_helper_file('helper_bad_chars_dieter')\n",
    "helper_contractions     = load_helper_file('helper_contractions')\n",
    "global_vocabulary       = load_helper_file('helper_global_vocabulary')\n",
    "global_vocabulary_chars = load_helper_file('helper_global_vocabulary_chars')\n",
    "normalized_chars        = load_helper_file('helper_normalized_chars')\n",
    "white_list_chars        = load_helper_file('helper_white_list_chars')\n",
    "white_list_punct        = \" '*-.,?!/:;_()[]{}<>=\" + '\"'\n",
    "pictograms_to_emoji     = load_helper_file('helper_pictograms_to_emoji')\n",
    "helper_custom_synonyms     = load_helper_file('helper_custom_synonyms')\n",
    "emoji_dict = set(e for lang in emoji.UNICODE_EMOJI.values() for e in lang)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "## Load Data\n",
    "good_cols       = ['_id', 'text']\n",
    "data = pd.read_parquet('../../data/bitcoin_twitter_raw/part_0.parquet')\n",
    "data = data.iloc[:20000][good_cols]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Initial State:\n",
      "Unknown words: 63451 | Known words: 6880\n"
     ]
    }
   ],
   "source": [
    "## Start preprocessing\n",
    "texts = data['text']\n",
    "local_vocab = bert_uncased_vocabulary\n",
    "global_lower=True\n",
    "texts = texts.astype(str)\n",
    "if verbose: print('#' *20 ,'Initial State:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Lowering everything:\n",
      "Unknown words: 54216 | Known words: 7938\n"
     ]
    }
   ],
   "source": [
    "def lower(texts):\n",
    "    texts = texts.apply(lambda x: x.lower())\n",
    "    if verbose: print('#'*10 ,'Step - Lowering everything:'); check_vocab(texts, local_vocab)\n",
    "    return texts\n",
    "\n",
    "if global_lower:\n",
    "    texts = texts.pipe(lower)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Normalize chars and dots:\n",
      "Unknown words: 53957 | Known words: 7946\n"
     ]
    }
   ],
   "source": [
    "# Normalize chars and dots - SEE HELPER FOR DETAILS\n",
    "# Global\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,normalized_chars) for i in x.split()]))\n",
    "texts = texts.apply(lambda x: re.sub('\\(dot\\)', '.', x))\n",
    "texts = texts.apply(lambda x: deaccent(x))\n",
    "if verbose: print('#'*10 ,'Step - Normalize chars and dots:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Control Chars:\n",
      "Unknown words: 53957 | Known words: 7946\n"
     ]
    }
   ],
   "source": [
    "# Remove 'control' chars\n",
    "global_chars_list = list(set([c for line in texts for c in line]))\n",
    "chars_dict = {c:'' for c in global_chars_list if unicodedata.category(c)[0]=='C'}\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#'*10 ,'Step - Control Chars:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove hrefs:\n",
      "Unknown words: 53957 | Known words: 7946\n"
     ]
    }
   ],
   "source": [
    "# Remove hrefs\n",
    "texts = texts.apply(lambda x: re.sub(re.findall(r'\\<a(.*?)\\>', x)[0], '', x) if (len(re.findall(r'\\<a (.*?)\\>', x))>0) and ('href' in re.findall(r'\\<a (.*?)\\>', x)[0]) else x)\n",
    "if verbose: print('#'*10 ,'Step - Remove hrefs:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove Bad Symbols:\n",
      "Unknown words: 53826 | Known words: 7956\n",
      "ð›ë¹„ä»·ð’•å—ð–Žð¥ð–—â‚ºðŸ†ƒðŸ²ã€‘ë‚˜ï¼„ð–“Ñµç•™ðŸà¹„ð€ð‘³ðŸ…·ðŸµð’â©à¸„ð–”é“¾ðŸ‡¸ë¡œé™†ðŸŽâ–ˆê·¸Â¯å¯†à¸ˆì§€ìµð’“ð‘»íšŒðŸ‡³ðžðŸ‡·ð…ð¦ð–†ð–žðŸ‡¨å††â¯ðŸ‡»ð ð•½ì¤‘ð‚â‹°ã…œè·Œð’Œð’‚å‹å°âŸ¶ê¸¸ð–ší–‰ð‘¾ðŸ ð’ó ¢ðŸ‡¿ðŸ”â–´ì‹œÆ€æ¨¡ðŸ‡­æ¡ë°˜ó ´ðŸ‡®ê¹Œç‚®ðŸ‡§ðŸ…³ð¯ðŸ‡½ìˆ˜â‹¯ð–‰ð¬ð’…äº¤â–“ì—ë”â‚³âœ“â€ì¸ð–Šðšè´§çº¦ðŸ‡±ë‹¤â–ºðê®¤äº†ØŸíƒ‘å´ç¢³ìŠ¤ë°”â–‘ðŸ…¼ð’Žð–‹ðŸ‡©â€Œå¿Œë ¤ã… ðŸ‡¹ë‚´ðŸ‡²âŸ ë°à¸‚æ¶¨ð­í¬ê®†íŠ¸ðŸ‡´ë„ðŸ°à¸¿ðŸ™à¹†ð«ì•„ëŠ”ðŸ˜ëž¬à¸œë•ðŸšðŸ…½ð–•ð’ì •ó §ðŸ…»â¦ê¸°à¹à¸”â‚¿ð–˜ðŸ‡ºð–™ð‘¼ð–ˆå¸æƒ³ð’‰ó ¿å€¼â“œðŸ‡µè²¨ë‹ˆð’ŠåŠ¡à¸°â‚¦ì¤ðŸ‡¬ë¦¬âž¤ì„œë©´ã€ì½”ç‰¹ï¿¥ó ³ê°€å¯’å•†à¸Šð‘²ì…˜ð’”âƒ£áµ›ðŸ‡ªð¨â ðŸ‡¦ã†”ê¶ŒðŸ­ð’†ë ‡ð’„ó £ð’ðŸ…´ðŸ‡°ðŸ†‚é€šð–‘ê®‡ðŸ¬ð„ð¡ð•®ï¿¼ð®ðŸ“Ùªð’—\n",
      "119835 --- b\n",
      "48708 --- \n",
      "20215 --- \n",
      "119957 --- t\n",
      "22359 --- \n",
      "120206 --- i\n",
      "119845 --- l\n",
      "120215 --- r\n",
      "8378 --- \n",
      "127363 --- t\n"
     ]
    }
   ],
   "source": [
    "# Convert or remove Bad Symbols\n",
    "global_chars_list = list(set([c for line in texts for c in line]))\n",
    "chars = ''.join([c for c in global_chars_list if (c not in bert_char_list) and (c not in emoji_dict) and (c not in white_list_chars)])\n",
    "chars_dict = {}\n",
    "for char in chars:\n",
    "    try:\n",
    "        new_char = unicodedata.name(char).split()[-1:][0].lower()\n",
    "        if len(new_char)==1:\n",
    "            chars_dict[ord(char)] = new_char\n",
    "        else:\n",
    "            chars_dict[ord(char)] = ''\n",
    "    except:\n",
    "        chars_dict[ord(char)] = ''\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove Bad Symbols:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print(chars)\n",
    "if verbose: print_dict(chars_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove Bad Symbols PART 2:\n",
      "Unknown words: 53659 | Known words: 7949\n",
      "Â·Ø³Ð¸ÐºÛŒÑã€Šâ˜†ÑÚºØ¯ï¼à¸²Î¾ï¼ŸÑŒÐ»Ë¢à¸•à¸žÙ„Ø±Ù†Î¹à¸¥à¤•Ñå­¦ãƒˆç”Ÿãƒ³åŒºâˆšØªãƒ«à¸—â€žà¸™à¸§ã‚³ã‚¤Ð³â€¦ÐµØ«Ø¸Ð¼à¹€Ø®Ñ„ãƒ¼ã€‚ØµÐ·ÑƒÚ©Ù‚ã‚«Ú†Ñ†ãƒ’â—Ð²ä»®â‰¥à¸¡ÑŽØ¹ÛÏ€ÑˆÙˆØ´Ø¡Ñ‹Ð±â€ºå®‰à¸¢Ð´ãƒƒæ¯”Ù…Ð¶åŠ ì´ä¸‹Ø©Ð°à¤šÙ¹â‚¬â†’Ù€â‰ˆÙƒâ‚¹â€¢Ú¯Ù¾ã€‹Ñ€ã‚¿Ø­à¤¬à¸­ãƒŽÚ¾ä¸ŠØ¶Ø§à¤¯à¸à¤¾à¤…Ñ‚Ñ‡Ù‡ï¼ŒØ°Ð¿Ø¨Î²Ø¬ÙŠå¹³å¤§Ð¾Ùãƒ„âˆžÐ½\n",
      "183 --- \n",
      "1587 --- \n",
      "1080 --- i\n",
      "1082 --- \n",
      "1740 --- \n",
      "1089 --- \n",
      "12298 --- \n",
      "9734 --- \n",
      "1101 --- e\n",
      "1722 --- \n"
     ]
    }
   ],
   "source": [
    "# Remove Bad Symbols PART 2\n",
    "# Global\n",
    "global_chars_list = list(set([c for line in texts for c in line]))\n",
    "chars = 'Â·' + ''.join([c for c in global_chars_list if (c not in white_list_chars) and (c not in emoji_dict) and (c not in white_list_punct) and (ord(c)>256)])\n",
    "chars_dict = {}\n",
    "for char in chars:\n",
    "    try:\n",
    "        new_char = unicodedata.name(char).split()[-1:][0].lower()\n",
    "        if len(new_char)==1:\n",
    "            chars_dict[ord(char)] = new_char\n",
    "        else:\n",
    "            chars_dict[ord(char)] = ''\n",
    "    except:\n",
    "        chars_dict[ord(char)] = ''\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove Bad Symbols PART 2:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print(chars)\n",
    "if verbose: print_dict(chars_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - HTML tags:\n",
      "Unknown words: 53659 | Known words: 7949\n"
     ]
    }
   ],
   "source": [
    "# Remove html tags\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if ('<' in word) and ('>' in word):\n",
    "        for tag in html_tags:\n",
    "            if ('<'+tag+'>' in word) or ('</'+tag+'>' in word):\n",
    "                temp_dict[word] = BeautifulSoup(word, 'html5lib').text\n",
    "texts = texts.apply(lambda x: ' '.join([temp_dict.get(i, i) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - HTML tags:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Convert urls part 1:\n",
      "Unknown words: 39204 | Known words: 7949\n",
      "https://t.co/q8zs9n3kaa --- @URL[t.co]\n",
      "https://t.co/niqxaxb9ih --- @URL[t.co]\n",
      "https://t.co/blcrihln2i --- @URL[t.co]\n",
      "https://t.co/hxstfnzmqv --- @URL[t.co]\n",
      "https://t.co/b3vuuavpog --- @URL[t.co]\n",
      "https://t.co/fomn3ewz1w --- @URL[t.co]\n",
      "https://t.co/fh8f2dkcde --- @URL[t.co]\n",
      "https://t.co/f71875vzeu --- @URL[t.co]\n",
      "https://t.co/rlwrm3ovxj --- @URL[t.co]\n",
      "https://t.co/bbdycnjgy0 --- @URL[t.co]\n"
     ]
    }
   ],
   "source": [
    "# Remove links (There is valuable information in links (probably you will find a way to use it))\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "url_rule = r'(?P<url>https?://[^\\s]+)'\n",
    "temp_dict = {k:domain_search(k) for k in temp_vocab if k!= re.compile(url_rule).sub('url', k)}\n",
    "\n",
    "for word in temp_dict:\n",
    "    new_value = temp_dict[word]\n",
    "    if word.find('http')>2:\n",
    "        temp_dict[word] =  word[:word.find('http')] + ' ' + place_hold(new_value, URL_TAG)\n",
    "    else:\n",
    "        temp_dict[word] = place_hold(new_value, URL_TAG)\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Convert urls part 1:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Convert urls part 1.5:\n",
      "Unknown words: 39203 | Known words: 7949\n"
     ]
    }
   ],
   "source": [
    "# Remove twitter links\n",
    "temp_dict = {\n",
    "    f'{URL_TAG}[t.co]': ''\n",
    "}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict, skip_check=True) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Convert urls part 1.5:'); check_vocab(texts, local_vocab);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove escaped html:\n",
      "Unknown words: 39129 | Known words: 7951\n",
      "&amp;&amp; ---  and  and \n",
      "#jpmorganchase&amp;amp;co --- #jpmorganchase and amp;co\n",
      "-------------&gt; --- -------------\n",
      "&gt;coin --- coin\n",
      "soon-&gt; --- soon-\n",
      "order&gt;: --- order:\n",
      "&lt;$1 --- $1\n",
      "2nd,3rd&amp;4th --- 2nd,3rd and 4th\n",
      "&gt;1000% --- 1000%\n",
      "buy&amp;hold. --- buy and hold.\n"
     ]
    }
   ],
   "source": [
    "# Remove escaped html\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "symbols = {\n",
    "    '&quot;': '',\n",
    "    '&amp;': ' and ',\n",
    "    '&lt;': '',\n",
    "    '&gt;': '',\n",
    "}\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if any([rep in word for rep in symbols.keys()]):\n",
    "        new_word = word\n",
    "        for rep, to in symbols.items():\n",
    "            new_word = new_word.replace(rep, to)\n",
    "        temp_dict[word] = new_word\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict, skip_check=True) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove escaped html:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Convert urls part 2:\n",
      "Unknown words: 39129 | Known words: 7951\n",
      "www.maverick-tech.con --- @URL[maverick-tech.con]\n",
      ".www.rapidsnetwork.io --- @URL[rapidsnetwork.io]\n"
     ]
    }
   ],
   "source": [
    "# Convert urls part 2\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "\n",
    "for word in temp_vocab:\n",
    "    url_check = False\n",
    "    if 'file:' in word:\n",
    "        url_check = True\n",
    "    elif ('http' in word) or ('ww.' in word) or ('.htm' in word) or ('ftp' in word) or ('.php' in word) or ('.aspx' in word):\n",
    "        if 'Aww' not in word:\n",
    "            for d_zone in url_extensions:\n",
    "                if '.' + d_zone in word:\n",
    "                    url_check = True\n",
    "                    break\n",
    "    elif ('/' in word) and ('.' in word):\n",
    "        for d_zone in url_extensions:\n",
    "            if '.' + d_zone + '/' in word:\n",
    "                url_check = True\n",
    "                break\n",
    "\n",
    "    if url_check:\n",
    "        temp_dict[word] =  place_hold(domain_search(word), URL_TAG)\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Convert urls part 2:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Normalize pictograms:\n",
      "Unknown words: 39128 | Known words: 7951\n",
      ":-)! --- ðŸ˜!\n",
      ":))) --- ðŸ˜)\n",
      ":-) --- ðŸ˜\n",
      "â¬‡@crypto_off --- â¬‡@cryptðŸ˜®ff\n"
     ]
    }
   ],
   "source": [
    "# Normalize pictograms\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if len(re.compile('[a-zA-Z0-9]').sub('', word))>2:\n",
    "        for pict in pictograms_to_emoji:\n",
    "            if (pict in word) and (len(pict)>2):\n",
    "                temp_dict[word] = word.replace(pict, pictograms_to_emoji[pict])\n",
    "            elif pict==word:\n",
    "                temp_dict[word] = pictograms_to_emoji[pict]\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Normalize pictograms:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Isolate emoji:\n",
      "Unknown words: 36781 | Known words: 7975\n",
      "ðŸŽ±â€¼ðŸ‘„âš™ðŸ¿ðŸ¦‰ðŸ¦…â˜‘ðŸ’ŠðŸ›ŽðŸ‘¬ðŸ¥°ðŸ®ã€½ðŸ˜â™¥ðŸ¤–â˜¹ðŸ›ðŸ£â¯â™‚ðŸ¤žðŸ’µðŸ•µâœ‹ðŸ“ŒðŸ¤¢ðŸ­ðŸ“©ðŸ’ªðŸª¦ðŸ¥¸ðŸðŸ’²â„¢ðŸ¹ðŸ‚âš¡ðŸ’¡ðŸ¤¨ðŸ¤ŒðŸ¤§ðŸ¥•ðŸ˜¡â“â›…ðŸ˜ŸðŸ’´â™¦ðŸ¦µâ¬‡â—ðŸ¤ðŸš¦ðŸš£ðŸ”ðŸ»ðŸŒ™âŒðŸƒðŸ‘Œâ›½ðŸ’‡ðŸ’ðŸ‡â™ŽðŸ˜ŽðŸ’£ðŸ‘ŠðŸš˜ðŸ¥²â–«â£ðŸ·ðŸ’•ðŸš„ðŸ“ðŸ¤ ðŸ¦ˆðŸ™€ðŸ”›ðŸŒ–ðŸ’˜ðŸ˜ðŸŽ‰ðŸ”¼ðŸ’·ðŸ¸ðŸ˜†ðŸ…±ðŸ˜…ðŸ˜§âšœâž¡ðŸ”—ðŸ™ŠðŸ˜’ðŸª…ðŸŸ§ðŸŸ ðŸ§¡ðŸ«âœ³ðŸ¤¸ðŸ‘ðŸ›‘âŒ›ðŸ“žðŸš‚ðŸ—½ðŸ‘©ðŸŒ¼ðŸŸ¥ðŸŽ‡ðŸŽ©ðŸ“¦ðŸ’¶ðŸ„ðŸ•ºðŸ”¥ðŸ˜¢ðŸ˜šðŸ¥³â›µðŸ–ðŸ‘‰ðŸ—ðŸ¢ðŸ˜žðŸ’‰ðŸ“¯ðŸðŸŽ°ðŸ”¹ðŸ™ŒðŸ¤©â˜¢ðŸ™ƒâ„ðŸ—³ðŸŒ´ðŸ’¤ðŸ§¢ðŸ¤·ðŸ¤¡ðŸ˜­â™€ðŸŒŠâ¤µðŸ˜¨ðŸš«ðŸ™ˆðŸ»â²ðŸ¦§ðŸ“¹ðŸ¸âš½ðŸ¾ðŸ‘­ðŸ©¸ðŸŒ±ðŸ´ðŸ˜â›”ðŸ¦¢ðŸ¦ºðŸ¬ðŸŽ²ðŸ“¸ðŸŒ‡ðŸ˜¤ðŸ›’â¬ðŸŒ¿ðŸ‘ðŸŒ‘ðŸ˜¼ðŸ”’ðŸ•¯â¬œðŸ‘¸ðŸ¼ðŸŽ¨ðŸŒðŸŒƒâ±ðŸ°ðŸ—£ðŸ¼ðŸ’±ðŸ“—ðŸš‘ðŸŸ©ðŸ…°ðŸ’°ðŸ’ƒðŸ‹ðŸ¤´ðŸŒðŸ“ºâ›´ðŸ˜”ðŸŽ¢ðŸ¿ðŸ‘¤ðŸ’³ðŸ”¯ðŸ’ŒðŸ”¶ðŸ¤¦ðŸ’¨ðŸ¥±ðŸŒ²ðŸˆâž–ðŸ³ðŸ¤¯â­ðŸƒðŸ¹ðŸ‘¾ðŸ‘ºðŸ˜¯â¤´ðŸ˜™ðŸŽŸðŸ¦ðŸ’¥ðŸŸ¢ðŸ¤¤ðŸ˜‹ðŸ¤³ðŸ¥ðŸŒ•ðŸ¡ðŸ¦®ðŸ«‚ðŸŠðŸ”«ðŸ¥’ðŸ’ðŸ””ðŸ˜„ðŸ‘†ðŸš—ðŸ––ðŸŒðŸŒ˜â¬…ðŸŒðŸ¤£ðŸ˜›â‡â›³ðŸ•˜ðŸŒªðŸ˜ŒðŸŒ€ðŸ“°ðŸ”†ðŸ¼ðŸ¦¾ðŸ›¤ðŸ˜©ðŸ‘·ðŸ‘¨ðŸ˜¬ðŸ”Žâ«ðŸ’©â™»â°ðŸðŸ»ðŸ’”âœðŸ’­ðŸ‘½ðŸ¤—ðŸ”‹ðŸ¥´ðŸ”·ðŸ”ªðŸ§§ðŸŽµðŸ”˜ðŸ“šâœ¨ðŸŒ’â›ˆðŸ“…ðŸŒ›ðŸ¥‘ðŸŽŠðŸŒ¸ðŸ”ŠðŸ¦½ðŸŽ£âš’ðŸ˜ƒðŸŽžðŸŒ‹ðŸ¦žðŸ¦„ðŸ†™ðŸ„ðŸ¦‹ðŸ¦ŽðŸ’»ðŸ”µðŸ˜‰ðŸ¥¬ðŸ¤”ðŸ§ ðŸ’¦ðŸµâš«â–¶â”ðŸ‘¶ðŸš©ðŸš‹ðŸ›€ðŸ¥‰ðŸ¦¡ðŸ—‘âœˆâš”ðŸŒŒðŸ¡ðŸ‘ŸðŸª™âšªðŸ”ŒðŸ’¯ðŸ§¨ðŸ‘ðŸ¯ðŸ’ ðŸ˜¶ðŸ’¸ðŸ‘‡ðŸ¾ðŸ“²âž•ðŸ™…ðŸ•ŠðŸš€ðŸ’“âŒšðŸ‘€ðŸŸðŸ¤¬ðŸ³ðŸ„ðŸŽðŸ¤ðŸ“ðŸŒ¹ðŸ˜´ðŸŽ–ðŸ¥œðŸŒ»â™£ðŸ‘‹ðŸ¥®ðŸ’§ã€°ðŸ˜‡ðŸ¥ºðŸŒ”â†—ðŸˆðŸŽ¤â¬†ðŸ¤ðŸŽ“ðŸšŠÂ©ðŸ˜€ðŸŒ ðŸ”¸ðŸŽ­ðŸ”ðŸš¶â˜•ðŸžâ¬›ðŸ¤²ðŸðŸ”ƒðŸ—»ðŸ¤“ðŸ’ŸðŸ¤­ðŸ“£ðŸ¥ƒðŸµðŸ“ˆðŸŒœðŸŽ†â˜®ðŸ¥‚Â®â˜€ðŸ¤˜ðŸŽ§ðŸ˜ðŸ™‹ðŸ¦•ðŸ¦šðŸ“†ðŸ¦ðŸ¦ðŸ¥…ðŸ§·ðŸŒžâš›ðŸ¦†ðŸ¥©ðŸ—“âœ”ðŸ¥€â•â˜ºðŸ¥“ðŸ¤ŸðŸ‘»ðŸ…ðŸ–ŒðŸ”ðŸŽ„ðŸŒŸðŸ’™â›ðŸ’œâ³ðŸ”–ðŸ˜–ðŸ”®ðŸ˜²ðŸŒˆðŸ”½ðŸ’›ðŸ‚ðŸ˜â™¾ðŸ“¢â¤ðŸŒ§ðŸ§¿ðŸ½ðŸ¥›ðŸ˜°ðŸ›«ðŸ¥žðŸ€ðŸ¦¬ðŸ“±ðŸ™„ðŸ”€â˜„â†ªðŸ¶ðŸ¦–ðŸ›°ðŸ§ðŸ§µâœ…â˜ ðŸ”ðŸ¥‡ðŸ’–âœŠðŸ˜ ðŸ’¬ðŸ†ðŸ†šðŸ–¤ðŸ› ðŸ˜‚ðŸ˜·ðŸ®ðŸ™†ðŸ˜¥ðŸƒðŸ‘‘ðŸš¨ðŸŽðŸ¦—ðŸŽðŸ”ºðŸ–â„¹ðŸššðŸ§„ðŸ†—ðŸŒ³ðŸ’—ðŸŽ¬ðŸ˜±ðŸ¤ðŸ“–ðŸŽðŸŸ¨ðŸ˜ŠðŸ¤ªðŸ”œâ˜ðŸŒ“ðŸºðŸ–¼ðŸŒâ›·ðŸ¤šðŸ‘•ðŸ™ðŸ¥µðŸŒ—ðŸ“ðŸ¥ŠðŸ§ðŸ†’ðŸ›¸ðŸ™‡ðŸ”¨ðŸ™‚ðŸ§ªâ˜ŽðŸ«ðŸŽ®ðŸ§ðŸ¤œðŸ‘ˆðŸ˜ˆðŸ‹ðŸ‘£ðŸ’«ðŸ¤™ðŸ§¸ðŸ”‘ðŸ“‰ðŸ˜‘ðŸ“¡ðŸ‘¥ðŸ•·ðŸ”‚ðŸðŸ¦â™‰ðŸ’¼ðŸ‘ðŸ˜»ðŸ”„ðŸ˜³ðŸ¤«ðŸ–•ðŸ’‹ðŸŽ¯ðŸ¦ŠðŸºðŸªðŸ™ðŸš†ðŸ”ŸðŸ”»ðŸ©ðŸ’žðŸ§šðŸ ðŸ§˜ðŸ˜«â—½ðŸ§™ðŸŽ¥ðŸ’ŽðŸ’ðŸ¦‘â‰ðŸ–‡ðŸ™ðŸŽˆðŸŽ¦ðŸ¥¥ðŸ•¶ðŸ§¯ðŸ‘‚ðŸª–ðŸ·ðŸ”´ðŸ¤‘âš â›“ðŸ¥¶ðŸŒšðŸ¾ðŸ¥ˆðŸ‘ðŸ’šâœŒðŸ˜œðŸ’¹ðŸ¤›ðŸ’€ðŸ˜˜ðŸ“ŠðŸ”±ðŸ‘¹ðŸ˜ªðŸ€ðŸ›¡ðŸ—¨ðŸ˜“ðŸš’ðŸ•ðŸŒŽâ˜â–ªâ›ªðŸ§‘ðŸ“â†©ðŸ¦ðŸŽ¶ðŸ˜®ðŸ²ðŸ‘ŽðŸ•ðŸ˜µ\n"
     ]
    }
   ],
   "source": [
    "# Isolate emoji\n",
    "# Global\n",
    "global_chars_list = list(set([c for line in texts for c in line]))\n",
    "chars = ''.join([c for c in global_chars_list if c in emoji_dict])\n",
    "chars_dict = {ord(c):f' {c} ' for c in chars}\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Isolate emoji:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print(chars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Duplicated Chars:\n",
      "Unknown words: 34752 | Known words: 8029\n"
     ]
    }
   ],
   "source": [
    "# Duplicated dots, question marks and exclamations\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    if (Counter(word)['.']>1) or (Counter(word)['!']>1) or (Counter(word)['?']>1) or (Counter(word)[',']>1):\n",
    "        if (Counter(word)['.']>1):\n",
    "            new_word = re.sub('\\.\\.+', ' . . . ', new_word)\n",
    "        if (Counter(word)['!']>1):\n",
    "            new_word = re.sub('\\!\\!+', ' ! ! ! ', new_word)\n",
    "        if (Counter(word)['?']>1):\n",
    "            new_word = re.sub('\\?\\?+', ' ? ? ? ', new_word)\n",
    "        if (Counter(word)[',']>1):\n",
    "            new_word = re.sub('\\,\\,+', ' , , , ', new_word)\n",
    "        temp_dict[word] = new_word\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Duplicated Chars:'); check_vocab(texts, local_vocab);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove underscore:\n",
      "Unknown words: 34738 | Known words: 8029\n",
      "_____________ --- \n",
      "__________ --- \n",
      "________ --- \n",
      "#_ --- #\n",
      "#a__ --- #a\n",
      "\\_()_/ --- \\()/\n",
      "#___ --- #\n",
      "_____________________ --- \n",
      "____ --- \n",
      "________________________ --- \n"
     ]
    }
   ],
   "source": [
    "# Remove underscore for spam words\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if (len(re.compile('[a-zA-Z0-9\\-\\.\\,\\/\\']').sub('', word))/len(word) > 0.6) and ('_' in word):\n",
    "        temp_dict[word] = re.sub('_', '', word)\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove underscore:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Spam chars repetition:\n",
      "Unknown words: 34729 | Known words: 8029\n",
      "**** ---  * \n",
      "*** ---  * \n",
      ")))) ---  ) \n",
      "::::::::::::::::::::::::::: ---  : \n",
      "$$$$$$$$$$$$ ---  $ \n",
      "$$$$ ---  $ \n",
      "***** ---  * \n",
      "$$$ ---  $ \n",
      "$$$$$ ---  $ \n"
     ]
    }
   ],
   "source": [
    "# Isolate spam chars repetition\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if (len(re.compile('[a-zA-Z0-9\\-\\.\\,\\/\\']').sub('', word))/len(word) > 0.6) and (len(Counter(word))==1) and (len(word)>2):\n",
    "        temp_dict[word] = ' '.join([' ' + next(iter(Counter(word).keys())) + ' ' for i in range(1)])\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Spam chars repetition:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Normalize pictograms part 2:\n",
      "Unknown words: 34724 | Known words: 8029\n",
      "=) --- ðŸ˜\n",
      ":) --- ðŸ˜\n",
      ";) --- ðŸ˜œ\n",
      ":] --- ðŸ˜\n",
      ":( --- ðŸ˜¡\n"
     ]
    }
   ],
   "source": [
    "# Normalize pictograms part 2\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if len(re.compile('[a-zA-Z0-9]').sub('', word))>1:\n",
    "        for pict in pictograms_to_emoji:\n",
    "            if pict==word:\n",
    "                temp_dict[word] = pictograms_to_emoji[pict]\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Normalize pictograms part 2:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Brackets and quotes:\n",
      "Unknown words: 33135 | Known words: 8088\n",
      "40 ---  ( \n",
      "41 ---  ) \n",
      "91 ---  [ \n",
      "93 ---  ] \n",
      "123 ---  { \n",
      "125 ---  } \n",
      "60 ---  < \n",
      "62 ---  > \n",
      "34 ---  \" \n"
     ]
    }
   ],
   "source": [
    "# Isolate brakets and quotes\n",
    "# Global\n",
    "chars = '()[]{}<>\"'\n",
    "chars_dict = {ord(c):f' {c} ' for c in chars}\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Brackets and quotes:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print_dict(chars_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Break long words:\n",
      "Unknown words: 32745 | Known words: 8106\n",
      "24/7 --- 24 / 7\n",
      "Â£1.46/ --- Â£1.46 / \n",
      "fil/usdt --- fil / usdt\n",
      "coinomics/tokenomics --- coinomics / tokenomics\n",
      "$0.00/tx --- $0.00 / tx\n",
      "android/apple --- android / apple\n",
      "health/inner --- health / inner\n",
      "btc/usdt --- btc / usdt\n",
      "2/9/21 --- 2 / 9 / 21\n",
      "/#eth ---  / #eth\n"
     ]
    }
   ],
   "source": [
    "# Break short words\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_vocab = [k for k in temp_vocab if len(k)<=20]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if '/' in word and not word.startswith('u/') and not word.startswith('r/'):\n",
    "        temp_dict[word] = re.sub('/', ' / ', word)\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Break long words:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Break long words:\n",
      "Unknown words: 32747 | Known words: 8110\n",
      "week/month/year/decade --- week / month / year / decade\n",
      "crypto-dinner-futures --- crypto dinner futures\n",
      "/jonathan/gabriel/ozo ---  / jonathan / gabriel / ozo\n",
      "cryptosmartnow@gmail.com --- cryptosmartnow@gmail . com\n",
      "0.078-0.085-0.099-0.105-0.12 --- 0.078 0.085 0.099 0.105 0.12\n",
      "jnjamor2020@gmail.com --- jnjamor2020@gmail . com\n",
      "chat@cryptoquestion.tech --- chat@cryptoquestion . tech\n",
      "#quality_over_quantity --- #quality over quantity\n",
      "every-once-in-a-while, --- every-once-in-a-while , \n",
      "#the_bull_run_has_just_started. --- #the_bull_run_has_just_started . \n",
      "########## Step - Break long words:\n",
      "Unknown words: 32745 | Known words: 8110\n",
      "#the_bull_run_has_just_started --- #the bull run has just started\n",
      "casino-partner/stakeholder --- casino-partner / stakeholder\n",
      "pullback/consolidation --- pullback / consolidation\n",
      "every-once-in-a-while --- every once in a while\n",
      "august/september/october --- august / september / october\n",
      "########## Step - Break long words:\n",
      "Unknown words: 32745 | Known words: 8110\n"
     ]
    }
   ],
   "source": [
    "# Break long words\n",
    "def break_long_words(texts):\n",
    "    temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "    temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "    temp_vocab = [k for k in temp_vocab if len(k)>20]\n",
    "\n",
    "    temp_dict = {}\n",
    "    for word in temp_vocab:\n",
    "        if '_' in word:\n",
    "            temp_dict[word] = re.sub('_', ' ', word)\n",
    "        elif '/' in word and not word.startswith('u/') and not word.startswith('r/'):\n",
    "            temp_dict[word] = re.sub('/', ' / ', word)\n",
    "        elif len(' '.join(word.split('-')).split())>2:\n",
    "            temp_dict[word] = re.sub('-', ' ', word)\n",
    "        for s in ',.:;':\n",
    "            if s in word and not re.compile('[+#@$/,.:;-]').sub('', word).isnumeric():\n",
    "                temp_dict[word] = word.replace(s, f' {s} ')\n",
    "\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - Break long words:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "for i in range(3):\n",
    "    texts = texts.pipe(break_long_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Disambiguate entities:\n",
      "Unknown words: 32635 | Known words: 8111\n",
      "mex$100 --- mex $100\n",
      "~$80 --- ~ $80\n",
      ".#online --- . #online\n",
      ".@paypal --- . @paypal\n",
      "tight.#hodler --- tight. #hodler\n",
      "+$42k --- + $42k\n",
      "pumps@so --- pumps @so\n",
      "328.71eur.#crypto --- 328.71eur. #crypto\n",
      "bag!#altcoins --- bag! #altcoins\n",
      "+$5k --- + $5k\n"
     ]
    }
   ],
   "source": [
    "# TODO: add number parsing before\n",
    "# Diambiguate entities\n",
    "# Split words on @,# and $ to clear up ambiguities between entitites\n",
    "symbols = '@#$'\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and ('@' in k or '#' in k or '$' in k)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    for symbol in symbols:\n",
    "        if symbol not in word: continue\n",
    "        left, *right = word.split(symbol)\n",
    "        rightz = symbol.join(right)\n",
    "        if len(left) > 0 and len(right[0]) > 0 and right[0].isalnum():\n",
    "            temp_dict[word] = f'{left} {symbol}{rightz}'\n",
    "        break\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Disambiguate entities:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 32603 | Known words: 8111\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n"
     ]
    }
   ],
   "source": [
    "def custom_synonyms(texts):\n",
    "    temp_dict = {}\n",
    "    for wfrom, wto in helper_custom_synonyms.items():\n",
    "        temp_dict[wfrom] = wto\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - Custom word synonyms:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "texts = texts.pipe(custom_synonyms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 32236 | Known words: 8111\n",
      "#first --- @HTAG[first]\n",
      "#chiliz --- @HTAG[chiliz]\n",
      "#vouchers --- @HTAG[vouchers]\n",
      "@stockheadau! --- @USR[stockheadau!]\n",
      "#cnnindonesia --- @HTAG[cnnindonesia]\n",
      "#awaamkojeenaydoniazi --- @HTAG[awaamkojeenaydoniazi]\n",
      "#cross --- @HTAG[cross]\n",
      "@btcclicks --- @USR[btcclicks]\n",
      "#tradingeducation --- @HTAG[tradingeducation]\n",
      "#freeaungsansuukyi --- @HTAG[freeaungsansuukyi]\n"
     ]
    }
   ],
   "source": [
    "# Remove/Convert usernames and hashtags\n",
    "def extract_entities(texts):\n",
    "    temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "    temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "    temp_dict = {}\n",
    "    for word in temp_vocab:\n",
    "        if (len(word) > 2) and (word[1:len(word)-1].replace('\\'s', '').replace('_', '').isalnum()):\n",
    "            new_word = word.replace('\\'s', '')\n",
    "            if not re.compile('[#@$/,.:;]').sub('', new_word).isnumeric():\n",
    "                new_word = re.compile('[,.:;]').sub('', new_word)\n",
    "                if word.startswith('@'):\n",
    "                    temp_dict[word] = place_hold(new_word[1:], USER_TAG)\n",
    "                elif word.startswith('#'):\n",
    "                    temp_dict[word] = place_hold(new_word[1:], HASH_TAG)\n",
    "                elif word.startswith('u/'):\n",
    "                    temp_dict[word] = place_hold(new_word[2:], USER_TAG)\n",
    "                elif word.startswith('r/'):\n",
    "                    temp_dict[word] = place_hold(new_word[2:], HASH_TAG)\n",
    "                elif word.startswith('$') and word[1:].isalpha():\n",
    "                    temp_dict[word] = place_hold(new_word[1:], CURRENCY_TAG)\n",
    "    temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - UserName and Hashtag:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "texts = texts.pipe(extract_entities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 31634 | Known words: 8111\n",
      "@HTAG[trx] --- @CURR[trx]\n",
      "@HTAG[xcur] --- @CURR[xcur]\n",
      "@HTAG[uamy] --- @CURR[uamy]\n",
      "@HTAG[up] --- @CURR[up]\n",
      "@HTAG[unl] --- @CURR[unl]\n",
      "@HTAG[dec] --- @CURR[dec]\n",
      "@USR[dec] --- @CURR[dec]\n",
      "@HTAG[orn] --- @CURR[orn]\n",
      "@HTAG[zen] --- @CURR[zen]\n",
      "@HTAG[stmx] --- @CURR[stmx]\n"
     ]
    }
   ],
   "source": [
    "# Hashtag and currency union\n",
    "def hashtag_currency_union(texts):\n",
    "    temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "    temp_vocab = set([k for k in temp_vocab if not check_replace(k)])\n",
    "    temp_dict = {}\n",
    "    for w in temp_vocab:\n",
    "        if w.startswith(CURRENCY_TAG):\n",
    "            if w.replace(CURRENCY_TAG, HASH_TAG) in temp_vocab:\n",
    "                temp_dict[w.replace(CURRENCY_TAG, HASH_TAG)] = w\n",
    "            if w.replace(CURRENCY_TAG, USER_TAG) in temp_vocab:\n",
    "                temp_dict[w.replace(CURRENCY_TAG, USER_TAG)] = w\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict, skip_check=True) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - Hashtag and currency union:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "texts = texts.pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove ending underscore:\n",
      "Unknown words: 31633 | Known words: 8111\n",
      "usdt_ --- usdt\n",
      "'fu__ --- 'fu\n"
     ]
    }
   ],
   "source": [
    "# Remove ending underscore (or add quotation marks???)\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and ('_' in k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    if word[len(word)-1]=='_':\n",
    "        for i in range(len(word),0,-1):\n",
    "            if word[i-1]!='_':\n",
    "                new_word = word[:i]\n",
    "                temp_dict[word] = new_word\n",
    "                break\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove ending underscore:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove starting underscore:\n",
      "Unknown words: 31633 | Known words: 8111\n"
     ]
    }
   ],
   "source": [
    "# Remove starting underscore\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and ('_' in k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    if word[0]=='_':\n",
    "        for i in range(len(word)):\n",
    "            if word[i]!='_':\n",
    "                new_word = word[i:]\n",
    "                temp_dict[word] = new_word\n",
    "                break\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove starting underscore:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - End word punctuations:\n",
      "Unknown words: 23495 | Known words: 8586\n",
      "wife. --- wife .\n",
      "days, --- days ,\n",
      "20. --- 20 .\n",
      "corrupt, --- corrupt ,\n",
      "death! --- death !\n",
      "credits: --- credits :\n",
      "$avax: --- $avax :\n",
      "usdt, --- usdt ,\n",
      "what. --- what .\n",
      "volando. --- volando .\n"
     ]
    }
   ],
   "source": [
    "# End word punctuations\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and (not k[len(k)-1].isalnum())]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    for i in range(len(word),0,-1):\n",
    "        if word[i-1].isnumeric() and re.compile('[$Â£%â‚¬]').match(word[i]):\n",
    "            break\n",
    "\n",
    "        if word[i-1].isalnum():\n",
    "            new_word = word[:i] + ' ' + word[i:]\n",
    "            break\n",
    "    temp_dict[word] = new_word\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - End word punctuations:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21408 | Known words: 8606\n",
      "$0.65 --- @NUM[65.0] dollar\n",
      "$0.032 --- @NUM[32.0] dollar\n",
      "10-15k --- 10 15k\n",
      "10-k --- 10 k\n",
      "$584m --- @NUM[584000000.0] dollar\n",
      "404,101.38 --- @NUM[40410138.0]\n",
      "~$40.8k --- around @NUM[408000.0] dollar\n",
      "38727.83 --- @NUM[3872783.0]\n",
      "280k --- @NUM[280000.0]\n",
      "4.462665btc --- @NUM[4462665.0] btc\n",
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21215 | Known words: 8606\n",
      "10x --- @NUM[10.0] times\n",
      "0.45800 --- @NUM[45800.0]\n",
      "3.76 --- @NUM[376.0]\n",
      "$3 --- @NUM[3.0] dollar\n",
      "$46 --- @NUM[46.0] dollar\n",
      "35xxx --- @NUM[35.0] xxx\n",
      "1k --- @NUM[1000.0]\n",
      "50k --- @NUM[50000.0]\n",
      "~3 --- around @NUM[3.0]\n",
      "25% --- @NUM[25.0] percent\n",
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21213 | Known words: 8606\n",
      "300$5001000$2000 --- @NUM[300.0] dollar 5001000$2000\n",
      "^24 --- @NUM[24.0]\n",
      "78$ --- @NUM[78.0] dollar\n",
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21213 | Known words: 8606\n",
      "5001000$2000 --- @NUM[5001000.0] dollar 2000\n"
     ]
    }
   ],
   "source": [
    "scale_mapping = {\n",
    "    'b': 1000000000,\n",
    "    'bn': 1000000000,\n",
    "    'bln': 1000000000,\n",
    "    'billion': 1000000000,\n",
    "    'm': 1000000,\n",
    "    'mn': 1000000,\n",
    "    'mln': 1000000,\n",
    "    'million': 1000000,\n",
    "    'k': 1000,\n",
    "    'thousand': 1000,\n",
    "    '-': -1,\n",
    "}\n",
    "\n",
    "translate = {\n",
    "    '$': 'dollar', 'Â£': 'pound','%': 'percent', 'â‚¬': 'euro'\n",
    "}\n",
    "\n",
    "translate_suffix = {\n",
    "    'x': 'times'\n",
    "}\n",
    "\n",
    "translate_prefix = {\n",
    "    '~': 'around',\n",
    "    '+-': 'around',\n",
    "    '@': 'at',\n",
    "    '=': 'equals',\n",
    "    '*#': 'ranked',\n",
    "    '#': 'ranked',\n",
    "}\n",
    "\n",
    "def serialize_numbers(texts):\n",
    "    temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "    temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "    temp_dict = {}\n",
    "    re_inb = re.compile('[.,\\'\"`]')\n",
    "    re_num = re.compile('^(~|\\+-|@|=|#|\\*#)?[-@+*^#:]?[$Â£%â‚¬]?(([.:]?[0-9])+)[$Â£%â‚¬]?')\n",
    "    re_fix = re.compile('^[$Â£%â‚¬][-+][0-9]')\n",
    "    for word in temp_vocab:\n",
    "        prefilter = re_inb.sub('', word).replace(',', '.')\n",
    "        if re_fix.search(prefilter):\n",
    "            prefilter = prefilter[1] + prefilter[0] + prefilter[2:]\n",
    "        result = re_num.search(prefilter)\n",
    "\n",
    "        if result and result.pos == 0:\n",
    "            # Process combined numbers / ranges in next iteration\n",
    "            if '-' in word and not word.startswith('-') and not word.startswith('+-'):\n",
    "                temp_dict[word] = ' '.join(word.split('-'))\n",
    "                continue\n",
    "\n",
    "            main_part = prefilter[:result.end()]\n",
    "            prefix = ''\n",
    "            for prefix_key, prefix_name in translate_prefix.items():\n",
    "                if main_part.startswith(prefix_key):\n",
    "                    prefix = prefix_name\n",
    "                    main_part = main_part.replace(prefix_key, '', 1)\n",
    "                    break\n",
    "\n",
    "            main = re.compile('^[~@+*^#:]').sub('',main_part)\n",
    "            currency = re.compile('[$Â£%â‚¬]').search(main)\n",
    "            currency = main[currency.start():currency.end()] if currency else None\n",
    "            main = re.compile('[$Â£%â‚¬]').sub('', main)\n",
    "            suffix = prefilter[result.end():]\n",
    "\n",
    "            multiplier = 1\n",
    "            if re.compile('\\.[0-9]{1,2}$').search(main): # decimal\n",
    "                multiplier *= 0.01 if main[-1].isnumeric() else 0.1\n",
    "            if '-' in main: # Neg numbers\n",
    "                multiplier *= -1\n",
    "                main = main.replace('-', '')\n",
    "            # Textual scale\n",
    "            if suffix in scale_mapping:\n",
    "                multiplier *= scale_mapping[suffix]\n",
    "                suffix = ''\n",
    "            if suffix in translate_suffix:\n",
    "                suffix = translate_suffix[suffix]\n",
    "\n",
    "            number = round(float(main.replace('.', '').replace(':', '')) * multiplier, 2)\n",
    "            # print(f'{number}  /  {currency}  /  {suffix}  /  {word}')\n",
    "            # noinspection PyTypeChecker\n",
    "            temp_dict[word] = ' '.join(filter(len,[\n",
    "                prefix,\n",
    "                place_hold(str(number), NUMBER_TAG),\n",
    "                translate[currency] if currency else '',\n",
    "                suffix\n",
    "            ]))\n",
    "\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - Serialize numbers:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "\n",
    "# Clean up numbers\n",
    "for i in range(4):\n",
    "    texts = texts.pipe(serialize_numbers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 21200 | Known words: 8606\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 21037 | Known words: 8606\n",
      "$usdt --- @CURR[usdt]\n",
      "$usd --- @CURR[usd]\n",
      "$aapl --- @CURR[aapl]\n",
      "$hai --- @CURR[hai]\n",
      "$bch --- @CURR[bch]\n",
      "$strax --- @CURR[strax]\n",
      "$riot --- @CURR[riot]\n",
      "#cryptocurrencies --- @HTAG[cryptocurrencies]\n",
      "$comp --- @CURR[comp]\n",
      "$arbkf --- @CURR[arbkf]\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "@HTAG[elt] --- @CURR[elt]\n",
      "@HTAG[crypto] --- @CURR[crypto]\n",
      "@HTAG[batman] --- @CURR[batman]\n",
      "@HTAG[tezos] --- @CURR[tezos]\n",
      "@USR[tezos] --- @CURR[tezos]\n",
      "@HTAG[fma] --- @CURR[fma]\n",
      "@HTAG[defi] --- @CURR[defi]\n",
      "@HTAG[bitcoin] --- @CURR[bitcoin]\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Start word punctuations:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "'science --- ' science\n",
      "*telegram --- * telegram\n",
      ".could --- . could\n",
      "*police --- * police\n",
      "-it --- - it\n",
      "*q --- * q\n",
      ".you --- . you\n",
      "\\4241491.0 --- \\ 4241491.0\n",
      "~the --- ~ the\n",
      "Â£5 --- Â£ 5\n"
     ]
    }
   ],
   "source": [
    "# Start word punctuations\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and (not k[0].isalnum() and k[0] not in ['@', '#', '$'])]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    for i in range(len(word)):\n",
    "        if word[i].isalnum() or word[i] in ['#', '@', '$']:\n",
    "            new_word = word[:i] + ' ' + word[i:]\n",
    "            break\n",
    "    temp_dict[word] = new_word\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "# texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Start word punctuations:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 21029 | Known words: 8606\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Find and replace acronims:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "g.o.a.t --- word_placeholder[goat]\n",
      "p.o.d --- word_placeholder[pod]\n",
      "f.i.a.t --- word_placeholder[fiat]\n"
     ]
    }
   ],
   "source": [
    "# Find and replace acronims\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if (Counter(word)['.']>1) and (check_replace(word)):\n",
    "        if (domain_search(word)!='') and (('www' in word) or (Counter(word)['/']>3)):\n",
    "            temp_dict[word] = place_hold('url ' + domain_search(word))\n",
    "        else:\n",
    "            if (re.compile('[\\.\\,]').sub('', word) in local_vocab) and (len(re.compile('[0-9\\.\\,\\-\\/\\:]').sub('', word))>0):\n",
    "                temp_dict[word] =  place_hold(re.compile('[\\.\\,]').sub('', word))\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Find and replace acronims:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Contractions:\n",
      "Unknown words: 20967 | Known words: 8606\n",
      "i'd --- i would\n",
      "this's --- this is\n",
      "he's --- he is\n",
      "shouldn't --- should not\n",
      "ya'll --- you will\n",
      "can't --- cannot\n",
      "when's --- when is\n",
      "who's --- who is\n",
      "you've --- you have\n",
      "they're --- they are\n"
     ]
    }
   ],
   "source": [
    "# Apply spellchecker for contractions\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and (\"'\" in k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if word in helper_contractions:\n",
    "        temp_dict[word] = helper_contractions[word] # place_hold(helper_contractions[word])\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Contractions:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove \"s:\n",
      "Unknown words: 20745 | Known words: 8617\n",
      "c's --- c\n",
      "sucker's --- sucker\n",
      "satoshi's --- satoshi\n",
      "#ether's --- #ether\n",
      "greeneum's --- greeneum\n",
      "case's --- case\n",
      "@microstrategy's --- @microstrategy\n",
      "robinhood's --- robinhood\n",
      "quantum's --- quantum\n",
      "bridgewater's --- bridgewater\n"
     ]
    }
   ],
   "source": [
    "# Remove 's (DO WE NEED TO REMOVE IT???)\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {k:k[:-2] for k in temp_vocab if (check_replace(k)) and (k.lower()[-2:]==\"'s\")}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove \"s:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Convert backslash:\n",
      "Unknown words: 20745 | Known words: 8617\n",
      "\\4241491.0 ---  / 4241491.0\n",
      "\\4301056.0 ---  / 4301056.0\n",
      "\\5058389.0 ---  / 5058389.0\n",
      "\\4299147.0 ---  / 4299147.0\n",
      "\\4233436.0 ---  / 4233436.0\n",
      "\\4238285.0 ---  / 4238285.0\n",
      "\\4240291.0 ---  / 4240291.0\n"
     ]
    }
   ],
   "source": [
    "# Convert backslash\n",
    "# Global\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and ('\\\\' in k)]\n",
    "temp_dict = {k:re.sub('\\\\\\\\+', ' / ', k) for k in temp_vocab}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Convert backslash:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 20745 | Known words: 8617\n",
      "5058389.0 --- @NUM[50583890.0]\n",
      "4301056.0 --- @NUM[43010560.0]\n",
      "4240291.0 --- @NUM[42402910.0]\n",
      "4238285.0 --- @NUM[42382850.0]\n",
      "4233436.0 --- @NUM[42334360.0]\n",
      "4299147.0 --- @NUM[42991470.0]\n",
      "4241491.0 --- @NUM[42414910.0]\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 20738 | Known words: 8617\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 20702 | Known words: 8617\n",
      "#telcoin --- @HTAG[telcoin]\n",
      "#cryptocurrencies --- @HTAG[cryptocurrencies]\n",
      "#nyzo --- @HTAG[nyzo]\n",
      "@iohk_charles --- @USR[iohk_charles]\n",
      "@thedaomaker --- @USR[thedaomaker]\n",
      "#cryptocurrency --- @HTAG[cryptocurrency]\n",
      "@petermccormack --- @USR[petermccormack]\n",
      "@cointelegraph --- @USR[cointelegraph]\n",
      "$doge --- @CURR[doge]\n",
      "#silver --- @HTAG[silver]\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 20688 | Known words: 8617\n",
      "@USR[dogecoin] --- @CURR[dogecoin]\n",
      "@USR[sylo] --- @CURR[sylo]\n",
      "@HTAG[crypto] --- @CURR[crypto]\n",
      "@HTAG[tesla] --- @CURR[tesla]\n",
      "@USR[tesla] --- @CURR[tesla]\n",
      "@USR[sofi] --- @CURR[sofi]\n",
      "@HTAG[ether] --- @CURR[ether]\n",
      "@HTAG[cme] --- @CURR[cme]\n",
      "@HTAG[nyzo] --- @CURR[nyzo]\n",
      "@USR[paypal] --- @CURR[paypal]\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Dup chars (with vocab check):\n",
      "Unknown words: 20436 | Known words: 8654\n",
      "niine --- nine\n",
      "ayyyyyeeeee --- aye\n",
      "thousaaaaaand --- thousand\n",
      "canvass --- canvas\n",
      "ooh --- oh\n",
      "bounceeeee --- bounce\n",
      "brrr --- br\n",
      "yeahhh --- yeah\n",
      "richhh --- rich\n",
      "untill --- until\n"
     ]
    }
   ],
   "source": [
    "# Try remove duplicated chars (not sure about this!!!!!). TODO check fist against vocab?\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "\n",
    "temp_dict = {}\n",
    "temp_vocab_dup = []\n",
    "\n",
    "for word in temp_vocab:\n",
    "    if not word.isalpha():\n",
    "        continue\n",
    "    temp_vocab_dup.append(''.join(ch for ch, _ in itertools.groupby(word)))\n",
    "temp_vocab_dup = set(temp_vocab_dup)\n",
    "temp_vocab_dup = temp_vocab_dup.difference(temp_vocab_dup.difference(set(local_vocab)))\n",
    "\n",
    "for word in temp_vocab:\n",
    "    new_word = ''.join(ch for ch, _ in itertools.groupby(word))\n",
    "    if new_word in temp_vocab_dup:\n",
    "        temp_dict[word] = new_word\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if (k != v) and (v in local_vocab)}\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Dup chars (with vocab check):'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 20436 | Known words: 8654\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 20436 | Known words: 8654\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 20436 | Known words: 8654\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 20436 | Known words: 8654\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Isolate numbers:\n",
      "Unknown words: 20436 | Known words: 8654\n",
      ":-6.11 --- word_placeholder[:-6.11]\n",
      "*_100% --- word_placeholder[*_100%]\n"
     ]
    }
   ],
   "source": [
    "# Isolate numbers\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if re.compile('[a-zA-Z]').sub('', word) == word:\n",
    "        if re.compile('[0-9]').sub('', word) != word:\n",
    "            temp_dict[word] = word\n",
    "\n",
    "global_chars_list = list(set([c for line in temp_dict for c in line]))\n",
    "chars = ''.join([c for c in global_chars_list if not c.isdigit()])\n",
    "chars_dict = {ord(c):f' {c} ' for c in chars}\n",
    "temp_dict = {k:place_hold(k) for k in temp_dict}\n",
    "\n",
    "#texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Isolate numbers:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Join dashes:\n",
      "Unknown words: 20430 | Known words: 8654\n",
      "clockwork--up --- clockwork-up\n",
      "--designed --- -designed\n",
      "outshined--cryptocurrency --- outshined-cryptocurrency\n",
      "----- --- -\n",
      "------------- --- -\n",
      "#crypto!--where --- #crypto!-where\n",
      "--- --- -\n",
      "-- --- -\n",
      "aa--tag --- aa-tag\n",
      "------------------------------------------ --- -\n"
     ]
    }
   ],
   "source": [
    "# Join dashes\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    temp_dict[word] = re.sub('\\-\\-+', '-', word)\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Join dashes:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Try Split word:\n",
      "Unknown words: 20430 | Known words: 8654\n"
     ]
    }
   ],
   "source": [
    "# Try join word (Sloooow)\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and (Counter(k)['-']>1)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = ''.join(['' if c in '-' else c for c in word])\n",
    "    if (new_word in local_vocab) and (len(new_word)>3):\n",
    "        temp_dict[word] = new_word\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Try Split word:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Try Split word:\n",
      "Unknown words: 19331 | Known words: 8753\n",
      "price:0.0000000019 --- price : 0 . 0000000019\n",
      "'science ---  ' science\n",
      "solidity-based --- solidity - based\n",
      "geo-location --- geo - location\n",
      "##btc ---  #  # btc\n",
      "ðŸ§¡ ---  ðŸ§¡ \n",
      "ðŸš‚ ---  ðŸš‚ \n",
      "ðŸ– ---  ðŸ– \n",
      "target:47716.95 --- target : 47716 . 95\n",
      "ðŸ’Œ ---  ðŸ’Œ \n"
     ]
    }
   ],
   "source": [
    "# Try Split word\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if len(re.compile('[a-zA-Z0-9\\*]').sub('', word))>0:\n",
    "        chars = re.compile('[a-zA-Z0-9\\*]').sub('', word)\n",
    "        temp_dict[word] = ''.join([' ' + c + ' ' if c in chars else c for c in word])\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Try Split word:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - L33T (with vocab check):\n",
      "Unknown words: 19327 | Known words: 8756\n",
      "t13 --- tie\n",
      "or3 --- ore\n",
      "sh1t --- shit\n",
      "fa1 --- fai\n"
     ]
    }
   ],
   "source": [
    "# L33T vocabulary (SLOW)\n",
    "# https://simple.wikipedia.org/wiki/Leet\n",
    "# Local (only unknown words)\n",
    "def convert_leet(word):\n",
    "    # basic conversion\n",
    "    word = re.sub('0', 'o', word)\n",
    "    word = re.sub('1', 'i', word)\n",
    "    word = re.sub('3', 'e', word)\n",
    "    word = re.sub('\\$', 's', word)\n",
    "    word = re.sub('\\@', 'a', word)\n",
    "    return word\n",
    "\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = convert_leet(word)\n",
    "    if (new_word!=word):\n",
    "        if (len(word)>2) and (new_word in local_vocab):\n",
    "            temp_dict[word] = new_word\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - L33T (with vocab check):'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 19298 | Known words: 8757\n",
      "588 --- @NUM[588.0]\n",
      "43000 --- @NUM[43000.0]\n",
      "2511 --- @NUM[2511.0]\n",
      "012736 --- @NUM[12736.0]\n",
      "47716 --- @NUM[47716.0]\n",
      "2421 --- @NUM[2421.0]\n",
      "2272 --- @NUM[2272.0]\n",
      "078 --- @NUM[78.0]\n",
      "07059741519 --- @NUM[7059741519.0]\n",
      "047 --- @NUM[47.0]\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 19294 | Known words: 8757\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 19283 | Known words: 8757\n",
      "@bitstamp --- @USR[bitstamp]\n",
      "#cryptocurrencies --- @HTAG[cryptocurrencies]\n",
      "$doge --- @CURR[doge]\n",
      "$trx --- @CURR[trx]\n",
      "@binance --- @USR[binance]\n",
      "$btc --- @CURR[btc]\n",
      "#altcoins --- @HTAG[altcoins]\n",
      "$eth --- @CURR[eth]\n",
      "#hodl --- @HTAG[hodl]\n",
      "#crypto --- @HTAG[crypto]\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 19282 | Known words: 8757\n",
      "@HTAG[crypto] --- @CURR[crypto]\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Open Holded words:\n",
      "Unknown words: 19279 | Known words: 8759\n"
     ]
    }
   ],
   "source": [
    "# Remove placeholders\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if (not check_replace(k) and k.startswith(WPLACEHOLDER))]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    temp_dict[word] = re.sub('___', ' ', word[17:-1])\n",
    "texts = texts.apply(lambda x: ' '.join([temp_dict.get(i, i) for i in x.split()]))\n",
    "texts = texts.apply(lambda x: ' '.join([i for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Open Holded words:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Multiple form:\n",
      "Unknown words: 18977 | Known words: 8832\n",
      "feedbacks --- feedback\n",
      "coincides --- coincide\n",
      "declarations --- declaration\n",
      "panics --- panic\n",
      "repays --- repay\n",
      "showdowns --- showdown\n",
      "informations --- information\n",
      "evolves --- evolve\n",
      "harvests --- harvest\n",
      "anyways --- anyway\n"
     ]
    }
   ],
   "source": [
    "# Search multiple form\n",
    "# Local | example -> flashlights / flashlight -> False / True\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (k[-1:]=='s') and (len(k)>4)]\n",
    "temp_dict = {k:k[:-1] for k in temp_vocab if (k[:-1] in local_vocab)}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Multiple form:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 18977 | Known words: 8832\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 18977 | Known words: 8832\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 18977 | Known words: 8832\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 18977 | Known words: 8832\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: 0.03805000000000003\n",
      "########## Step - Language datection:\n",
      "Unknown words: 17403 | Known words: 8681\n"
     ]
    }
   ],
   "source": [
    "# Cut away non english tweets\n",
    "model = fasttext.load_model('../../data/kaggle/lid.176.ftz')\n",
    "\n",
    "def langcheck(item, min_confidence=0.2):\n",
    "    text = ' '.join([w for w in item.split() if not w.startswith('@')])\n",
    "    if len(text) < 3:\n",
    "        return True\n",
    "    results = dict(zip(*model.predict(text, k=2)))\n",
    "    return results.get('__label__en', 0) > min_confidence\n",
    "\n",
    "mask = texts.parallel_map(langcheck)\n",
    "if verbose: print(f'Deleted: {1 - sum(mask)/len(texts)}')\n",
    "texts = texts[mask]\n",
    "data = data[mask]\n",
    "if verbose: print('#' * 10, 'Step - Language datection:'); check_vocab(texts, local_vocab);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                       _id  \\\n0      1360142875330232324   \n1      1360140112861003776   \n2      1360137307047694337   \n4      1360132401142366210   \n5      1360131434158170113   \n...                    ...   \n19995  1357792968455946242   \n19996  1357792933982928896   \n19997  1357792930359107588   \n19998  1357792864005095424   \n19999  1357792837870510083   \n\n                                                                                                                                                                                                          text  \n0      when the top u . s . central banker gets photobombed by @CURR[btc] . ðŸ‘‰ ðŸ‘€ @CURR[bitcoin] @CURR[bitcoin] @HTAG[cryptocurrency] @HTAG[cryptocurrency] @HTAG[ethereum] @HTAG[ripple] @CURR[link] @HTAG[c...  \n1      best am arriving with exciting features @CURR[bsc] @USR[binance] @CURR[bitcoin] @HTAG[binancesmartchain] @CURR[defi] @HTAG[definews] @HTAG[stafi] @CURR[cake] @HTAG[pancakeswap] @HTAG[paraswap] @HT...  \n2      to keep its ultra bullish run intact , @CURR[egld] bulls need to keep @CURR[egld] / @CURR[usdt] daily above @NUM[148.0] dollar . reclaiming @NUM[174.0] dollar would be superb . break @NUM[148.0] d...  \n4      next coin that goes @NUM[100.0] percent . . . buckle up . . . @CURR[xtz] @CURR[xtz] @CURR[tezos] look @ my calls from last 2 weeks @CURR[iota] @CURR[coti] tezos will move hard incoming days . @CUR...  \n5                        its gonna be huge ! ðŸš€ ðŸ˜ ðŸ‘‘ @HTAG[fetch_ai] ðŸ‘‘ @CURR[xrp] @HTAG[vechain] @HTAG[chainlink] @HTAG[cardano] @HTAG[algorand] @HTAG[altcoins] @HTAG[artificialintelligence] @HTAG[blockchain]  \n...                                                                                                                                                                                                        ...  \n19995                                                                                                                                                                             cash is trash @CURR[bitcoin]  \n19996                                                                                               global central bank efforts to limit u . s . dollars decline raises specter of currency war @CURR[bitcoin]  \n19997                                                                                                                                       what if @CURR[bitcoin] is a social experiment ? well , money was .  \n19998                                                                                                       @CURR[bitcoin] btw that was pre close ny - cme friday dump . pl are closing positions b4 weekend .  \n19999                                                                                                                                           nigeria is fucked and pregnant with stupidity . @CURR[bitcoin]  \n\n[19239 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1360142875330232324</td>\n      <td>when the top u . s . central banker gets photobombed by @CURR[btc] . ðŸ‘‰ ðŸ‘€ @CURR[bitcoin] @CURR[bitcoin] @HTAG[cryptocurrency] @HTAG[cryptocurrency] @HTAG[ethereum] @HTAG[ripple] @CURR[link] @HTAG[c...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1360140112861003776</td>\n      <td>best am arriving with exciting features @CURR[bsc] @USR[binance] @CURR[bitcoin] @HTAG[binancesmartchain] @CURR[defi] @HTAG[definews] @HTAG[stafi] @CURR[cake] @HTAG[pancakeswap] @HTAG[paraswap] @HT...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1360137307047694337</td>\n      <td>to keep its ultra bullish run intact , @CURR[egld] bulls need to keep @CURR[egld] / @CURR[usdt] daily above @NUM[148.0] dollar . reclaiming @NUM[174.0] dollar would be superb . break @NUM[148.0] d...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1360132401142366210</td>\n      <td>next coin that goes @NUM[100.0] percent . . . buckle up . . . @CURR[xtz] @CURR[xtz] @CURR[tezos] look @ my calls from last 2 weeks @CURR[iota] @CURR[coti] tezos will move hard incoming days . @CUR...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1360131434158170113</td>\n      <td>its gonna be huge ! ðŸš€ ðŸ˜ ðŸ‘‘ @HTAG[fetch_ai] ðŸ‘‘ @CURR[xrp] @HTAG[vechain] @HTAG[chainlink] @HTAG[cardano] @HTAG[algorand] @HTAG[altcoins] @HTAG[artificialintelligence] @HTAG[blockchain]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>1357792968455946242</td>\n      <td>cash is trash @CURR[bitcoin]</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>1357792933982928896</td>\n      <td>global central bank efforts to limit u . s . dollars decline raises specter of currency war @CURR[bitcoin]</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>1357792930359107588</td>\n      <td>what if @CURR[bitcoin] is a social experiment ? well , money was .</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>1357792864005095424</td>\n      <td>@CURR[bitcoin] btw that was pre close ny - cme friday dump . pl are closing positions b4 weekend .</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>1357792837870510083</td>\n      <td>nigeria is fucked and pregnant with stupidity . @CURR[bitcoin]</td>\n    </tr>\n  </tbody>\n</table>\n<p>19239 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = texts\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TODO:\n",
    "* numbers\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}