{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# Credit for some parts to: https://www.kaggle.com/kyakovlev/preprocessing-bert-public\n",
    "# Number extraction and hashtags is my baby\n",
    "\n",
    "# General imports|  \n",
    "import pandas as pd\n",
    "import re, warnings, pickle, itertools, emoji, unicodedata\n",
    "\n",
    "# custom imports\n",
    "from gensim.utils import deaccent\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "from utils.datasets import *\n",
    "from pandarallel import pandarallel\n",
    "import fasttext\n",
    "\n",
    "pandarallel.initialize()\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = 10\n",
    "pd.options.display.max_colwidth = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "## Initial vars\n",
    "\n",
    "HELPER_PATH             = '../../data/helpers/'\n",
    "LOCAL_TEST = True       ## Local test - for test performance on part of the train set only\n",
    "verbose = True\n",
    "WPLACEHOLDER = 'word_placeholder'\n",
    "URL_TAG = '@URL'\n",
    "USER_TAG = '@USR'\n",
    "NUMBER_TAG = '@NUM'\n",
    "HASH_TAG = '@HTAG'\n",
    "CURRENCY_TAG = '@CURR'\n",
    "IMMUTABLES = [WPLACEHOLDER, URL_TAG, USER_TAG, NUMBER_TAG, HASH_TAG, CURRENCY_TAG]\n",
    "\n",
    "SEED = 42               ## Seed for enviroment\n",
    "seed_everything(SEED)   ## Seed everything"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "## Preprocess helpers\n",
    "def place_hold(w, tag=WPLACEHOLDER):\n",
    "    return tag + '[' + re.sub(' ', '___', w) + ']'\n",
    "\n",
    "## Helpers\n",
    "def check_replace(w):\n",
    "    return not bool(re.search('|'.join(IMMUTABLES), w))\n",
    "\n",
    "def make_cleaning(s, c_dict):\n",
    "    if check_replace(s):\n",
    "        s = s.translate(c_dict)\n",
    "    return s\n",
    "\n",
    "def make_dict_cleaning(s, w_dict, skip_check=False):\n",
    "    # Replaces a word using dict if it is mutable\n",
    "    if skip_check or check_replace(s):\n",
    "        s = w_dict.get(s, s)\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "## Get basic helper data\n",
    "\n",
    "bert_uncased_vocabulary = load_helper_file('helper_bert_uncased_vocabulary')\n",
    "bert_cased_vocabulary   = load_helper_file('helper_bert_cased_vocabulary')\n",
    "bert_char_list          = list(set([c for line in bert_uncased_vocabulary+bert_cased_vocabulary for c in line]))\n",
    "\n",
    "url_extensions          = load_helper_file('helper_url_extensions')\n",
    "html_tags               = load_helper_file('helper_html_tags')\n",
    "good_chars_dieter       = load_helper_file('helper_good_chars_dieter')\n",
    "bad_chars_dieter        = load_helper_file('helper_bad_chars_dieter')\n",
    "helper_contractions     = load_helper_file('helper_contractions')\n",
    "global_vocabulary       = load_helper_file('helper_global_vocabulary')\n",
    "global_vocabulary_chars = load_helper_file('helper_global_vocabulary_chars')\n",
    "normalized_chars        = load_helper_file('helper_normalized_chars')\n",
    "white_list_chars        = load_helper_file('helper_white_list_chars')\n",
    "white_list_punct        = \" '*-.,?!/:;_()[]{}<>=\" + '\"'\n",
    "pictograms_to_emoji     = load_helper_file('helper_pictograms_to_emoji')\n",
    "helper_custom_synonyms     = load_helper_file('helper_custom_synonyms')\n",
    "emoji_dict = set(e for lang in emoji.UNICODE_EMOJI.values() for e in lang)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "## Load Data\n",
    "good_cols       = ['_id', 'text']\n",
    "data = pd.read_parquet('../../data/bitcoin_twitter_raw/part_0.parquet')\n",
    "data = data.iloc[:20000][good_cols]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Initial State:\n",
      "Unknown words: 63451 | Known words: 6880\n"
     ]
    }
   ],
   "source": [
    "## Start preprocessing\n",
    "texts = data['text']\n",
    "local_vocab = bert_uncased_vocabulary\n",
    "global_lower=True\n",
    "texts = texts.astype(str)\n",
    "if verbose: print('#' *20 ,'Initial State:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Lowering everything:\n",
      "Unknown words: 54216 | Known words: 7938\n"
     ]
    }
   ],
   "source": [
    "def lower(texts):\n",
    "    texts = texts.apply(lambda x: x.lower())\n",
    "    if verbose: print('#'*10 ,'Step - Lowering everything:'); check_vocab(texts, local_vocab)\n",
    "    return texts\n",
    "\n",
    "if global_lower:\n",
    "    texts = texts.pipe(lower)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Normalize chars and dots:\n",
      "Unknown words: 53957 | Known words: 7946\n"
     ]
    }
   ],
   "source": [
    "# Normalize chars and dots - SEE HELPER FOR DETAILS\n",
    "# Global\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,normalized_chars) for i in x.split()]))\n",
    "texts = texts.apply(lambda x: re.sub('\\(dot\\)', '.', x))\n",
    "texts = texts.apply(lambda x: deaccent(x))\n",
    "if verbose: print('#'*10 ,'Step - Normalize chars and dots:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Control Chars:\n",
      "Unknown words: 53957 | Known words: 7946\n"
     ]
    }
   ],
   "source": [
    "# Remove 'control' chars\n",
    "global_chars_list = list(set([c for line in texts for c in line]))\n",
    "chars_dict = {c:'' for c in global_chars_list if unicodedata.category(c)[0]=='C'}\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#'*10 ,'Step - Control Chars:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove hrefs:\n",
      "Unknown words: 53957 | Known words: 7946\n"
     ]
    }
   ],
   "source": [
    "# Remove hrefs\n",
    "texts = texts.apply(lambda x: re.sub(re.findall(r'\\<a(.*?)\\>', x)[0], '', x) if (len(re.findall(r'\\<a (.*?)\\>', x))>0) and ('href' in re.findall(r'\\<a (.*?)\\>', x)[0]) else x)\n",
    "if verbose: print('#'*10 ,'Step - Remove hrefs:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove Bad Symbols:\n",
      "Unknown words: 53826 | Known words: 7956\n",
      "ê·¸à¸‚ï¿¥ð’‚ê°€ð’Šå¸íŠ¸é€šð‘¼ê¸°ðŸ‡¹ì‹œðžð•½âƒ£ë”è²¨à¸¿ðŸ‡ºå—ðŸ‡¬Ùªð–Žé“¾ð¬ðŸ…·ð…íƒ‘ðŸ‡¸ð’‰ð’†ê®¤ðŸ…»í–‰íšŒð’ëž¬ð¡ëŠ”ì—ðŸ…³à¸”ðŸ‡·å€¼âŸ â–“ð–‘ó £ë°˜ðŸ˜ðŸ“ã†”ì¤‘ðŸ…´ã… â–ˆð’•æ¨¡ð‚ðŸ­ðŸ¬æ¶¨ð®ð’…ð–•â‚ºð–“â–ºðŸ™ë¹„ð å°ì§€ìµë‹ˆð•®ð–†ð–™â‹°ë‚˜ðŸ²ð‘³ðŸµðŸ…½ì¤ð¥ðŸ‡»Ñµâ©ðŸ‡½æƒ³ìŠ¤â ðŸ‡¿ê¶Œì •å¿Œð‘»ð’”ð„â¯ð¨áµ›ðŸ‡²ì•„ç•™à¸Šå††ë ‡à¹†å‹ð«ð’Œð–žë°”ê®†ð–”à¸°ðŸ…¼ðŸ‡°å¯’è·ŒðŸ†‚ë ¤ðŸà¸ˆð¦ðšï¿¼ð–ˆð–šðŸ‡ªâ€ŒðŸ°â‚¿ð’é™†ë¦¬ç‰¹ðŸšÆ€è´§ð‘¾ð€ì¸ð›ðŸ‡¦â¦ðŸ‡±ðŸ‡´ë°ìˆ˜í¬çº¦â€ó ¢â‚³ðŸ ðŸ‡µâ–´äº†ð’ð–Šà¸„ØŸâ–‘ê¹Œðð–‰ð’—ðŸ‡­ê®‡ó ³ë‚´â‹¯ð–‹ë„ð­ê¸¸æ¡äº¤ðŸ†ƒåŠ¡ë©´ð’ð‘²å´ã…œð’“à¹„ó ´ï¼„Â¯âž¤â‚¦ð¯ä»·â“œã€‘ð’Žð–—ë•ã€ðŸ”ðŸ‡®ð–˜ðŸ‡¨ë‹¤ó §à¹âœ“ðŸŽå¯†ç‚®ë¡œì„œðŸ‡§âŸ¶ç¢³ðŸ‡³ðŸ‡©å•†ð’„ì½”ó ¿ì…˜à¸œ\n",
      "44536 --- \n",
      "3586 --- \n",
      "65509 --- \n",
      "119938 --- a\n",
      "44032 --- \n",
      "119946 --- i\n",
      "24065 --- \n",
      "53944 --- \n",
      "36890 --- \n",
      "119932 --- u\n"
     ]
    }
   ],
   "source": [
    "# Convert or remove Bad Symbols\n",
    "global_chars_list = list(set([c for line in texts for c in line]))\n",
    "chars = ''.join([c for c in global_chars_list if (c not in bert_char_list) and (c not in emoji_dict) and (c not in white_list_chars)])\n",
    "chars_dict = {}\n",
    "for char in chars:\n",
    "    try:\n",
    "        new_char = unicodedata.name(char).split()[-1:][0].lower()\n",
    "        if len(new_char)==1:\n",
    "            chars_dict[ord(char)] = new_char\n",
    "        else:\n",
    "            chars_dict[ord(char)] = ''\n",
    "    except:\n",
    "        chars_dict[ord(char)] = ''\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove Bad Symbols:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print(chars)\n",
    "if verbose: print_dict(chars_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove Bad Symbols PART 2:\n",
      "Unknown words: 53659 | Known words: 7949\n",
      "Â·Ø¹ãƒ«åŒºâ—Ñ€ä¸‹ã‚³â˜†â†’Ø¬Ù„Ø­à¤…ã‚¿â€ºÚºØ©Ú†Ø³ãƒ³Ù…Ù¾ÙˆâˆšØ§ã€‹Ñ†Ùƒà¤¾å¤§Ð°ÑÙ€ä¸Šãƒ¼Ð¶Ú¾Ð½å¹³Ø¨Øµà¤•ÐµÚ¯ÛŒÐ¸ÑŒÐ±à¤¬Ø¸æ¯”Ð»Î¾Ð¾à¸¡à¸Ñˆà¸¥Ð¼ÙŠï¼Ÿï¼Œâ‰ˆâ€¦Ù¹ã€‚ã‚«à¸²ãƒŽÐ²ÑƒË¢Ï€âˆžØ¯Ø°Ð·Î²ÛÑÑ‡à¸¢Ø´à¤šà¸§â‰¥Ù‚ã‚¤Ñ‹Øªä»®à¸žÙ‡Ñ„åŠ ì´å­¦Ø±ãƒ’Ø¡Ø®â‚¹Ú©ÙÐ¿â‚¬Î¹Ù†Ð³Ø¶ÐºÐ´Ø«â€¢ãƒˆà¸•à¸—à¸­ï¼ã€ŠÑãƒ„Ñ‚ÑŽà¤¯â€žç”Ÿà¹€å®‰ãƒƒà¸™\n",
      "183 --- \n",
      "1593 --- \n",
      "12523 --- \n",
      "21306 --- \n",
      "9679 --- \n",
      "1088 --- \n",
      "19979 --- \n",
      "12467 --- \n",
      "9734 --- \n",
      "8594 --- \n"
     ]
    }
   ],
   "source": [
    "# Remove Bad Symbols PART 2\n",
    "# Global\n",
    "global_chars_list = list(set([c for line in texts for c in line]))\n",
    "chars = 'Â·' + ''.join([c for c in global_chars_list if (c not in white_list_chars) and (c not in emoji_dict) and (c not in white_list_punct) and (ord(c)>256)])\n",
    "chars_dict = {}\n",
    "for char in chars:\n",
    "    try:\n",
    "        new_char = unicodedata.name(char).split()[-1:][0].lower()\n",
    "        if len(new_char)==1:\n",
    "            chars_dict[ord(char)] = new_char\n",
    "        else:\n",
    "            chars_dict[ord(char)] = ''\n",
    "    except:\n",
    "        chars_dict[ord(char)] = ''\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove Bad Symbols PART 2:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print(chars)\n",
    "if verbose: print_dict(chars_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - HTML tags:\n",
      "Unknown words: 53659 | Known words: 7949\n"
     ]
    }
   ],
   "source": [
    "# Remove html tags\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if ('<' in word) and ('>' in word):\n",
    "        for tag in html_tags:\n",
    "            if ('<'+tag+'>' in word) or ('</'+tag+'>' in word):\n",
    "                temp_dict[word] = BeautifulSoup(word, 'html5lib').text\n",
    "texts = texts.apply(lambda x: ' '.join([temp_dict.get(i, i) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - HTML tags:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Convert urls part 1:\n",
      "Unknown words: 39204 | Known words: 7949\n",
      "https://t.co/7xykbxxwqa --- @URL[t.co]\n",
      "https://t.co/oacmyci1rs --- @URL[t.co]\n",
      "https://t.co/bzz4arutjn --- @URL[t.co]\n",
      "https://t.co/mgiy0tgnjb --- @URL[t.co]\n",
      "https://t.co/xpm4jqnfle --- @URL[t.co]\n",
      "https://t.co/smzw1qr4wd --- @URL[t.co]\n",
      "https://t.co/3mwzculmgv --- @URL[t.co]\n",
      "https://t.co/0l5zhv2ahh --- @URL[t.co]\n",
      "https://t.co/dflfmcfxnv --- @URL[t.co]\n",
      "https://t.co/apfpkyjacs --- @URL[t.co]\n"
     ]
    }
   ],
   "source": [
    "# Remove links (There is valuable information in links (probably you will find a way to use it))\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "url_rule = r'(?P<url>https?://[^\\s]+)'\n",
    "temp_dict = {k:domain_search(k) for k in temp_vocab if k!= re.compile(url_rule).sub('url', k)}\n",
    "\n",
    "for word in temp_dict:\n",
    "    new_value = temp_dict[word]\n",
    "    if word.find('http')>2:\n",
    "        temp_dict[word] =  word[:word.find('http')] + ' ' + place_hold(new_value, URL_TAG)\n",
    "    else:\n",
    "        temp_dict[word] = place_hold(new_value, URL_TAG)\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Convert urls part 1:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Convert urls part 1.5:\n",
      "Unknown words: 39203 | Known words: 7949\n"
     ]
    }
   ],
   "source": [
    "# Remove twitter links\n",
    "temp_dict = {\n",
    "    f'{URL_TAG}[t.co]': ''\n",
    "}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict, skip_check=True) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Convert urls part 1.5:'); check_vocab(texts, local_vocab);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove escaped html:\n",
      "Unknown words: 39129 | Known words: 7951\n",
      "&amp;&amp; ---  and  and \n",
      "&gt;11% --- 11%\n",
      "s&amp;p --- s and p\n",
      "(&gt;10x). --- (10x).\n",
      "--&gt; --- --\n",
      "&lt; --- \n",
      "&lt;- --- -\n",
      "&lt;30 --- 30\n",
      "&gt;&gt;&gt;&gt; --- \n",
      "youtube--&gt; --- youtube--\n"
     ]
    }
   ],
   "source": [
    "# Remove escaped html\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "symbols = {\n",
    "    '&quot;': '',\n",
    "    '&amp;': ' and ',\n",
    "    '&lt;': '',\n",
    "    '&gt;': '',\n",
    "}\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if any([rep in word for rep in symbols.keys()]):\n",
    "        new_word = word\n",
    "        for rep, to in symbols.items():\n",
    "            new_word = new_word.replace(rep, to)\n",
    "        temp_dict[word] = new_word\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict, skip_check=True) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove escaped html:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Convert urls part 2:\n",
      "Unknown words: 39129 | Known words: 7951\n",
      "www.maverick-tech.con --- @URL[maverick-tech.con]\n",
      ".www.rapidsnetwork.io --- @URL[rapidsnetwork.io]\n"
     ]
    }
   ],
   "source": [
    "# Convert urls part 2\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "\n",
    "for word in temp_vocab:\n",
    "    url_check = False\n",
    "    if 'file:' in word:\n",
    "        url_check = True\n",
    "    elif ('http' in word) or ('ww.' in word) or ('.htm' in word) or ('ftp' in word) or ('.php' in word) or ('.aspx' in word):\n",
    "        if 'Aww' not in word:\n",
    "            for d_zone in url_extensions:\n",
    "                if '.' + d_zone in word:\n",
    "                    url_check = True\n",
    "                    break\n",
    "    elif ('/' in word) and ('.' in word):\n",
    "        for d_zone in url_extensions:\n",
    "            if '.' + d_zone + '/' in word:\n",
    "                url_check = True\n",
    "                break\n",
    "\n",
    "    if url_check:\n",
    "        temp_dict[word] =  place_hold(domain_search(word), URL_TAG)\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Convert urls part 2:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Normalize pictograms:\n",
      "Unknown words: 39128 | Known words: 7951\n",
      ":-)! --- ðŸ˜!\n",
      ":))) --- ðŸ˜)\n",
      "â¬‡@crypto_off --- â¬‡@cryptðŸ˜®ff\n",
      ":-) --- ðŸ˜\n"
     ]
    }
   ],
   "source": [
    "# Normalize pictograms\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if len(re.compile('[a-zA-Z0-9]').sub('', word))>2:\n",
    "        for pict in pictograms_to_emoji:\n",
    "            if (pict in word) and (len(pict)>2):\n",
    "                temp_dict[word] = word.replace(pict, pictograms_to_emoji[pict])\n",
    "            elif pict==word:\n",
    "                temp_dict[word] = pictograms_to_emoji[pict]\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Normalize pictograms:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Isolate emoji:\n",
      "Unknown words: 36781 | Known words: 7975\n",
      "ðŸ†âœ‹ðŸ™âž¡ðŸƒðŸŽ­ðŸ’€ðŸ›«ðŸ˜…ðŸ˜©ðŸºðŸ°ðŸ¤©â›´âž–ðŸŒŸðŸ¤ðŸ¤˜ðŸ˜ƒðŸ”œðŸ‘¨ðŸ›‘ðŸŽ°ðŸðŸ“¡ðŸ‚ðŸ™„ðŸ™‹ðŸŒŠðŸ§ªðŸ³ðŸ”¹ðŸ”¼ðŸ¤­ðŸ–¤ðŸ•ºðŸ’žðŸ¦‘ðŸ’ŸðŸ¿âž•ðŸ•˜ðŸ¤”ðŸŒ”âš›ðŸ‡ðŸ§§â›…ðŸ¦ŠðŸ”ðŸ“†ðŸ¥’ðŸ™€ðŸ¥ŠðŸŽðŸ™ƒðŸ§ðŸ·ðŸ™…ðŸŽˆâœ…ðŸ”—ðŸ’˜â±ðŸ’‰ðŸ“Œâœ”ðŸ‘ðŸŽ¥ðŸ’·ðŸ˜”ðŸŽ²ðŸ¦¬ðŸ’¯âœˆðŸ¦žâ˜ ðŸ’µðŸ¦•ðŸ‘ðŸ˜‘ðŸ§¸ðŸ”–ðŸ‘©ðŸ˜°ðŸ˜†ðŸ¥³ðŸ”’ðŸŒˆðŸ”ŒðŸ´ðŸ––ðŸ¦¢ðŸŸ§ðŸ˜ðŸ‘­ðŸ§™ðŸ™‡ðŸ”ŠðŸ’£ðŸ¯ðŸ¸ðŸ”¸ðŸ¡ðŸ˜›ðŸŒðŸ’šðŸ‘€âŒ›ðŸŽ©â†©ðŸ‘‹ðŸ˜ŸðŸ”›ðŸ”«ðŸŽ‡ðŸŒ–ðŸ¥€ðŸ’™ðŸššðŸ¡ðŸŸ¢ðŸ…±ðŸ†šðŸ¥ˆðŸ¤¤ðŸµðŸ’¥ðŸ¥¥Â®ðŸ”¶ðŸ¸ðŸˆðŸª¦ðŸ’ƒðŸ”‚ðŸ¤ŒðŸ©ðŸ˜§ðŸ¢ðŸ¤“ðŸ˜™ðŸ¥¬ðŸš¦ðŸª…ðŸ”„â„¹ðŸ…ðŸŽžðŸ˜²ðŸ”·ðŸ“±ðŸ§ ðŸ’”ðŸ“žðŸ‘‘âš”ðŸ§¡ðŸª™ðŸŽ±ðŸ˜ªðŸ—£ðŸ’“ðŸŒ¿ðŸ“¯ðŸ«ðŸ”‹ðŸšŠðŸŸ¨â¤µðŸ˜‰ðŸ‘ŽðŸ˜¼ðŸ€ðŸ¤´ðŸŒ³ðŸ¥ƒðŸª–ðŸ”ªã€°ðŸ”˜â„ðŸ¥‰ðŸ«‚ðŸ“‰âš¡ðŸ‘ðŸ¤¬â¤´ðŸŒ’ðŸ™ðŸ˜»ðŸŽðŸ·ðŸ”ðŸ•¯ðŸ’–ðŸŒðŸ¤™â„¢ðŸ“…ðŸ”µðŸ§‘ðŸ”»ðŸ˜„ðŸ“£ðŸŽ–ðŸ‘£â¬†ðŸ„ðŸ’°ðŸ¤ðŸ§ðŸ”ºðŸŒžâ™€ðŸŒ§â†ªðŸŒðŸŒ—ðŸ’«ðŸŒ˜ðŸ’•ðŸ»âšªðŸ˜ðŸŒ•ðŸ¥®ðŸ¥¶ðŸ˜®ðŸ§˜ðŸŽ¨â“ðŸŽ¤ðŸ˜±ðŸŽ„ðŸ¤¯ðŸŒ‹ðŸ¤–ðŸŒšðŸ›€ðŸ˜“â›³ðŸ¤ªðŸ¥ºðŸš¨ðŸ¼ðŸ–•ðŸŽµâ˜ºðŸ”¨ðŸ’›ðŸš€ðŸ˜«â€¼ðŸ¥‘ðŸ§·ðŸš—ðŸ£ðŸðŸ¤ŸðŸ»ðŸ˜ˆðŸ•¶ðŸ˜¯ðŸ‘ŒðŸš¶âœŠðŸ¥°ðŸ‘¸ðŸŒªâ²ðŸ”ðŸ¦ºðŸ˜€âŒâ£ðŸ•ðŸ“â•ðŸ€ðŸŒ‡â‰ðŸ˜’â¤ðŸ‘½ðŸ¤¦ðŸŒ¼â™¾ðŸ‘»ðŸ™ŒðŸ’ðŸ’§ðŸ›’ðŸ¤£ðŸ’¶â›µðŸ‘¥ðŸŒƒðŸ“âš’â™‰ðŸŽŠðŸ¦Žâœ³ðŸ›°ðŸ¥‡ðŸ¥µðŸ‘„â™‚ðŸ‘·ðŸ¦†ðŸ˜ ðŸ”ƒðŸš©ðŸ¤³ðŸ’—ðŸ¦µðŸ’ŒðŸ”ðŸ„ðŸŽ¬ðŸ‘•â°ðŸ¥±ðŸ”€ðŸ½ðŸ¤›ðŸŽ¶ðŸ˜œðŸš‘ðŸ¤¸â™£â›”ðŸ˜¢ðŸ¦ðŸ’ðŸ›¤ðŸ¤¡Â©ã€½ðŸ“²ðŸ’¦ðŸ”®ðŸ ðŸŽ¢ðŸŒ¹ðŸ—‘â˜ŽðŸ”¥ðŸ˜¡ðŸ§¯ðŸ¾ðŸ’¼ðŸŸðŸ¤¨ðŸŽ‰ðŸ‚â›“ðŸŽâ˜•â”â˜ðŸ’‡ðŸ¤¢ðŸ²ðŸ˜´ðŸ”ŽðŸ˜³ðŸ¥¸ðŸŒ ðŸŒ›ðŸ•Šâ‡ðŸ‘ðŸŸ ðŸš„âš«ðŸ‘ðŸ¥‚ðŸ•µðŸ’´ðŸ™‚ðŸŽ¦ðŸ—ðŸ˜–ðŸ–ðŸ¦¾ðŸ¹ðŸ¤ðŸ˜‹â–ªðŸš‹ðŸ…°ðŸ¦ðŸ’œðŸ¥…ðŸŒðŸŒ»ðŸ¤§ðŸŒ™ðŸ¤ðŸ‘‚ðŸ˜ðŸ—³ðŸ¤«ðŸ¤‘ðŸ‘¶ðŸ¥žðŸ¤œðŸ“šðŸŒ²ðŸ¾ðŸºðŸ’¹ðŸŽ§ðŸ‹ðŸ¤ ðŸ¦½ðŸ“¢ðŸ’ŠðŸ¦ðŸˆâ†—ðŸ”½ðŸ“ŠðŸ“¹ðŸ¤²ðŸ¼ðŸ›ŽðŸ™ðŸ”Ÿâ˜ðŸ‘ºâ­ðŸ¦šðŸ‘¬ðŸ“°ðŸ§šâ˜‘ðŸ¥œðŸ†—ðŸŒœðŸ’­âšœðŸ’²âœðŸ†™ðŸ’¡ðŸŒ€ðŸ¥“ðŸ™ˆðŸ¥²â™»ðŸ¾ðŸðŸŒ¸ðŸ™†â˜€ðŸ˜·ðŸ–‡ðŸ“ˆðŸ’¸â«â™ŽðŸ¦—ðŸ—½ðŸ¿ðŸš’ðŸ›¡â—â¬…ðŸ¦ðŸ¥©ðŸ˜˜ðŸ”¯â¬‡ðŸ„â˜¢ðŸŽ®ðŸ˜‚â–¶ðŸ«ðŸŽŸðŸŸ¥ðŸ¥ðŸ‘‡ðŸ—»ðŸ—“ðŸ˜‡ðŸ””ðŸ‘ŠðŸ“ðŸžðŸ©¸ðŸ§¢ðŸ¦§ðŸ†’ðŸ˜¨ðŸ»ðŸ¥›â›·ðŸ‘¤âŒšðŸ›¸ðŸ•·â›ˆðŸ¦…ðŸ§„ðŸš«ðŸš£ðŸ˜¤ðŸ’ðŸŽ¯âœŒâ™¥ðŸ“¦ðŸ› ðŸŽ£ðŸ“—â›½ðŸ˜žðŸ‘¹ðŸ‘¾ðŸ§¿ðŸ˜¶âš½ðŸ˜µðŸŽ†ðŸ’‹â›ðŸ’¬ðŸ’¨ðŸ”±ðŸš˜ðŸ’©ðŸ¤žðŸ§ðŸ‘Ÿâ›ªðŸŒ´ðŸ¥´ðŸ’»ðŸµâ—½ðŸ˜šðŸâ¬›â˜®ðŸ¤šðŸ­ðŸ¦®ðŸš†ðŸ“ðŸŠðŸ˜ŠðŸ’³ðŸ’±â˜„ðŸ¬ðŸ˜¬ðŸŽ“ðŸ¦‰ðŸŸ©ðŸ’ªðŸ¤—ðŸ‘†ðŸ˜¥ðŸ®âœ¨ðŸ”†ðŸ¦ˆðŸ§¨ðŸŽðŸ¦¡â™¦ðŸ‘ˆðŸ¥•ðŸ’ŽðŸ˜­ðŸŒŽðŸ•ðŸ™ŠðŸ“ºðŸ“¸ðŸ”‘ðŸðŸƒðŸ§µâ¬œðŸ¦â³â–«ðŸ“©ðŸƒðŸ˜ðŸŒ‘â¯â¬ðŸ¼ðŸŒŒâš™ðŸ¹ðŸ—¨ðŸªðŸ‹ðŸ¦„ðŸŒ“ðŸ¦‹ðŸ–¼ðŸ’ ðŸ®ðŸ¤·ðŸ–ðŸ›ðŸ“–ðŸ˜ŒðŸ¶ðŸ’¤ðŸ–ŒðŸŒ±â˜¹ðŸ”´âš ðŸš‚ðŸ¦–ðŸ˜ðŸ‘‰ðŸ³ðŸŒðŸ˜Ž\n"
     ]
    }
   ],
   "source": [
    "# Isolate emoji\n",
    "# Global\n",
    "global_chars_list = list(set([c for line in texts for c in line]))\n",
    "chars = ''.join([c for c in global_chars_list if c in emoji_dict])\n",
    "chars_dict = {ord(c):f' {c} ' for c in chars}\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Isolate emoji:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print(chars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Duplicated Chars:\n",
      "Unknown words: 34752 | Known words: 8029\n"
     ]
    }
   ],
   "source": [
    "# Duplicated dots, question marks and exclamations\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    if (Counter(word)['.']>1) or (Counter(word)['!']>1) or (Counter(word)['?']>1) or (Counter(word)[',']>1):\n",
    "        if (Counter(word)['.']>1):\n",
    "            new_word = re.sub('\\.\\.+', ' . . . ', new_word)\n",
    "        if (Counter(word)['!']>1):\n",
    "            new_word = re.sub('\\!\\!+', ' ! ! ! ', new_word)\n",
    "        if (Counter(word)['?']>1):\n",
    "            new_word = re.sub('\\?\\?+', ' ? ? ? ', new_word)\n",
    "        if (Counter(word)[',']>1):\n",
    "            new_word = re.sub('\\,\\,+', ' , , , ', new_word)\n",
    "        temp_dict[word] = new_word\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Duplicated Chars:'); check_vocab(texts, local_vocab);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove underscore:\n",
      "Unknown words: 34738 | Known words: 8029\n",
      "\\_()_/ --- \\()/\n",
      "_____? --- ?\n",
      "_____________________ --- \n",
      "#____ --- #\n",
      "#_ --- #\n",
      "^_^ --- ^^\n",
      "______ --- \n",
      "________________________ --- \n",
      "#___ --- #\n",
      "________ --- \n"
     ]
    }
   ],
   "source": [
    "# Remove underscore for spam words\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if (len(re.compile('[a-zA-Z0-9\\-\\.\\,\\/\\']').sub('', word))/len(word) > 0.6) and ('_' in word):\n",
    "        temp_dict[word] = re.sub('_', '', word)\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove underscore:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Spam chars repetition:\n",
      "Unknown words: 34729 | Known words: 8029\n",
      ")))) ---  ) \n",
      "$$$$$ ---  $ \n",
      "**** ---  * \n",
      "$$$$$$$$$$$$ ---  $ \n",
      "$$$$ ---  $ \n",
      "*** ---  * \n",
      "$$$ ---  $ \n",
      "***** ---  * \n",
      "::::::::::::::::::::::::::: ---  : \n"
     ]
    }
   ],
   "source": [
    "# Isolate spam chars repetition\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if (len(re.compile('[a-zA-Z0-9\\-\\.\\,\\/\\']').sub('', word))/len(word) > 0.6) and (len(Counter(word))==1) and (len(word)>2):\n",
    "        temp_dict[word] = ' '.join([' ' + next(iter(Counter(word).keys())) + ' ' for i in range(1)])\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Spam chars repetition:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Normalize pictograms part 2:\n",
      "Unknown words: 34724 | Known words: 8029\n",
      ":] --- ðŸ˜\n",
      ":) --- ðŸ˜\n",
      ":( --- ðŸ˜¡\n",
      "=) --- ðŸ˜\n",
      ";) --- ðŸ˜œ\n"
     ]
    }
   ],
   "source": [
    "# Normalize pictograms part 2\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if len(re.compile('[a-zA-Z0-9]').sub('', word))>1:\n",
    "        for pict in pictograms_to_emoji:\n",
    "            if pict==word:\n",
    "                temp_dict[word] = pictograms_to_emoji[pict]\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Normalize pictograms part 2:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Brackets and quotes:\n",
      "Unknown words: 33135 | Known words: 8088\n",
      "40 ---  ( \n",
      "41 ---  ) \n",
      "91 ---  [ \n",
      "93 ---  ] \n",
      "123 ---  { \n",
      "125 ---  } \n",
      "60 ---  < \n",
      "62 ---  > \n",
      "34 ---  \" \n"
     ]
    }
   ],
   "source": [
    "# Isolate brakets and quotes\n",
    "# Global\n",
    "chars = '()[]{}<>\"'\n",
    "chars_dict = {ord(c):f' {c} ' for c in chars}\n",
    "texts = texts.apply(lambda x: ' '.join([make_cleaning(i,chars_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Brackets and quotes:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print_dict(chars_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Break long words:\n",
      "Unknown words: 32745 | Known words: 8106\n",
      "$one/ --- $one / \n",
      "/coin ---  / coin\n",
      "12/25. --- 12 / 25.\n",
      "w/out --- w / out\n",
      "retweet/follow --- retweet / follow\n",
      "$iost/ --- $iost / \n",
      "govt/banks --- govt / banks\n",
      "bitcoin/alts --- bitcoin / alts\n",
      "bnb/usdt --- bnb / usdt\n",
      "$190,000/btc --- $190,000 / btc\n"
     ]
    }
   ],
   "source": [
    "# Break short words\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_vocab = [k for k in temp_vocab if len(k)<=20]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if '/' in word and not word.startswith('u/') and not word.startswith('r/'):\n",
    "        temp_dict[word] = re.sub('/', ' / ', word)\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Break long words:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Break long words:\n",
      "Unknown words: 32747 | Known words: 8110\n",
      "like/retweet/comment: --- like/retweet/comment : \n",
      "jnjamor2020@gmail.com --- jnjamor2020@gmail . com\n",
      "97/104/110/118/135/open --- 97 / 104 / 110 / 118 / 135 / open\n",
      "faster/cheaper/better --- faster / cheaper / better\n",
      "digital/cryptocurrency --- digital / cryptocurrency\n",
      "caaaaanntaaaareeee.oh.oh.oh.oh --- caaaaanntaaaareeee . oh . oh . oh . oh\n",
      "0.051500-0.05550-0.064000+ --- 0.051500 0.05550 0.064000+\n",
      "#fashion.#beautiful.#happy.#cute. --- #fashion . #beautiful . #happy . #cute . \n",
      "cryptosmartnow@gmail.com --- cryptosmartnow@gmail . com\n",
      "38400-38300-38100-38000-37850 --- 38400 38300 38100 38000 37850\n",
      "########## Step - Break long words:\n",
      "Unknown words: 32745 | Known words: 8110\n",
      "#the_bull_run_has_just_started --- #the bull run has just started\n",
      "casino-partner/stakeholder --- casino-partner / stakeholder\n",
      "pullback/consolidation --- pullback / consolidation\n",
      "august/september/october --- august / september / october\n",
      "every-once-in-a-while --- every once in a while\n",
      "########## Step - Break long words:\n",
      "Unknown words: 32745 | Known words: 8110\n"
     ]
    }
   ],
   "source": [
    "# Break long words\n",
    "def break_long_words(texts):\n",
    "    temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "    temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "    temp_vocab = [k for k in temp_vocab if len(k)>20]\n",
    "\n",
    "    temp_dict = {}\n",
    "    for word in temp_vocab:\n",
    "        if '_' in word:\n",
    "            temp_dict[word] = re.sub('_', ' ', word)\n",
    "        elif '/' in word and not word.startswith('u/') and not word.startswith('r/'):\n",
    "            temp_dict[word] = re.sub('/', ' / ', word)\n",
    "        elif len(' '.join(word.split('-')).split())>2:\n",
    "            temp_dict[word] = re.sub('-', ' ', word)\n",
    "        for s in ',.:;':\n",
    "            if s in word and not re.compile('[+#@$/,.:;-]').sub('', word).isnumeric():\n",
    "                temp_dict[word] = word.replace(s, f' {s} ')\n",
    "\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - Break long words:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "for i in range(3):\n",
    "    texts = texts.pipe(break_long_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Disambiguate entities:\n",
      "Unknown words: 32635 | Known words: 8111\n",
      "+500$bnb --- +500 $bnb\n",
      "chat@cryptoquestion --- chat @cryptoquestion\n",
      "$#link --- $ #link\n",
      "3$p --- 3 $p\n",
      ".@elonmusk --- . @elonmusk\n",
      ",#bitcoiners --- , #bitcoiners\n",
      "on:@mercatoxcom --- on: @mercatoxcom\n",
      "Â¿#tether --- Â¿ #tether\n",
      ".@peterschiff --- . @peterschiff\n",
      "more?#bitcoin --- more? #bitcoin\n"
     ]
    }
   ],
   "source": [
    "# TODO: add number parsing before\n",
    "# Diambiguate entities\n",
    "# Split words on @,# and $ to clear up ambiguities between entitites\n",
    "symbols = '@#$'\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and ('@' in k or '#' in k or '$' in k)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    for symbol in symbols:\n",
    "        if symbol not in word: continue\n",
    "        left, *right = word.split(symbol)\n",
    "        rightz = symbol.join(right)\n",
    "        if len(left) > 0 and len(right[0]) > 0 and right[0].isalnum():\n",
    "            temp_dict[word] = f'{left} {symbol}{rightz}'\n",
    "        break\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Disambiguate entities:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 32603 | Known words: 8111\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n"
     ]
    }
   ],
   "source": [
    "def custom_synonyms(texts):\n",
    "    temp_dict = {}\n",
    "    for wfrom, wto in helper_custom_synonyms.items():\n",
    "        temp_dict[wfrom] = wto\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - Custom word synonyms:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "texts = texts.pipe(custom_synonyms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 32236 | Known words: 8111\n",
      "#finanstwitter --- @HTAG[finanstwitter]\n",
      "@coinbureau --- @USR[coinbureau]\n",
      "#nolamboforme --- @HTAG[nolamboforme]\n",
      "#bnt --- @HTAG[bnt]\n",
      "$wrx --- @CURR[wrx]\n",
      "#hangseng --- @HTAG[hangseng]\n",
      "#cryptowealth --- @HTAG[cryptowealth]\n",
      "@dogeswap_ --- @USR[dogeswap_]\n",
      "@unistakefinance. --- @USR[unistakefinance]\n",
      "#iskcon --- @HTAG[iskcon]\n"
     ]
    }
   ],
   "source": [
    "# Remove/Convert usernames and hashtags\n",
    "def extract_entities(texts):\n",
    "    temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "    temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "    temp_dict = {}\n",
    "    for word in temp_vocab:\n",
    "        if (len(word) > 2) and (word[1:len(word)-1].replace('\\'s', '').replace('_', '').isalnum()):\n",
    "            new_word = word.replace('\\'s', '')\n",
    "            if not re.compile('[#@$/,.:;]').sub('', new_word).isnumeric():\n",
    "                new_word = re.compile('[,.:;]').sub('', new_word)\n",
    "                if word.startswith('@'):\n",
    "                    temp_dict[word] = place_hold(new_word[1:], USER_TAG)\n",
    "                elif word.startswith('#'):\n",
    "                    temp_dict[word] = place_hold(new_word[1:], HASH_TAG)\n",
    "                elif word.startswith('u/'):\n",
    "                    temp_dict[word] = place_hold(new_word[2:], USER_TAG)\n",
    "                elif word.startswith('r/'):\n",
    "                    temp_dict[word] = place_hold(new_word[2:], HASH_TAG)\n",
    "                elif word.startswith('$') and word[1:].isalpha():\n",
    "                    temp_dict[word] = place_hold(new_word[1:], CURRENCY_TAG)\n",
    "    temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - UserName and Hashtag:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "texts = texts.pipe(extract_entities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 31634 | Known words: 8111\n",
      "@HTAG[lbc] --- @CURR[lbc]\n",
      "@HTAG[chr] --- @CURR[chr]\n",
      "@HTAG[cciv] --- @CURR[cciv]\n",
      "@HTAG[yld] --- @CURR[yld]\n",
      "@HTAG[agi] --- @CURR[agi]\n",
      "@HTAG[sparta] --- @CURR[sparta]\n",
      "@HTAG[dg] --- @CURR[dg]\n",
      "@USR[cnet] --- @CURR[cnet]\n",
      "@HTAG[cbtc] --- @CURR[cbtc]\n",
      "@HTAG[sndl] --- @CURR[sndl]\n"
     ]
    }
   ],
   "source": [
    "# Hashtag and currency union\n",
    "def hashtag_currency_union(texts):\n",
    "    temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "    temp_vocab = set([k for k in temp_vocab if not check_replace(k)])\n",
    "    temp_dict = {}\n",
    "    for w in temp_vocab:\n",
    "        if w.startswith(CURRENCY_TAG):\n",
    "            if w.replace(CURRENCY_TAG, HASH_TAG) in temp_vocab:\n",
    "                temp_dict[w.replace(CURRENCY_TAG, HASH_TAG)] = w\n",
    "            if w.replace(CURRENCY_TAG, USER_TAG) in temp_vocab:\n",
    "                temp_dict[w.replace(CURRENCY_TAG, USER_TAG)] = w\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict, skip_check=True) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - Hashtag and currency union:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "texts = texts.pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove ending underscore:\n",
      "Unknown words: 31633 | Known words: 8111\n",
      "usdt_ --- usdt\n",
      "'fu__ --- 'fu\n"
     ]
    }
   ],
   "source": [
    "# Remove ending underscore (or add quotation marks???)\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and ('_' in k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    if word[len(word)-1]=='_':\n",
    "        for i in range(len(word),0,-1):\n",
    "            if word[i-1]!='_':\n",
    "                new_word = word[:i]\n",
    "                temp_dict[word] = new_word\n",
    "                break\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove ending underscore:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove starting underscore:\n",
      "Unknown words: 31633 | Known words: 8111\n"
     ]
    }
   ],
   "source": [
    "# Remove starting underscore\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and ('_' in k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    if word[0]=='_':\n",
    "        for i in range(len(word)):\n",
    "            if word[i]!='_':\n",
    "                new_word = word[i:]\n",
    "                temp_dict[word] = new_word\n",
    "                break\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove starting underscore:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - End word punctuations:\n",
      "Unknown words: 23495 | Known words: 8586\n",
      "wauw, --- wauw ,\n",
      "raised! --- raised !\n",
      "reality. --- reality .\n",
      "delivered! --- delivered !\n",
      "mark; --- mark ;\n",
      "has: --- has :\n",
      "its. --- its .\n",
      "sheet? --- sheet ?\n",
      "dr. --- dr .\n",
      "equity. --- equity .\n"
     ]
    }
   ],
   "source": [
    "# End word punctuations\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and (not k[len(k)-1].isalnum())]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    for i in range(len(word),0,-1):\n",
    "        if word[i-1].isnumeric() and re.compile('[$Â£%â‚¬]').match(word[i]):\n",
    "            break\n",
    "\n",
    "        if word[i-1].isalnum():\n",
    "            new_word = word[:i] + ' ' + word[i:]\n",
    "            break\n",
    "    temp_dict[word] = new_word\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - End word punctuations:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21677 | Known words: 8606\n",
      "+5.58% --- @NUM[5.58] percent\n",
      "-5.41% --- @NUM[-5.41] percent\n",
      "1,500 --- @NUM[1500.0]\n",
      "24-hour --- 24 hour\n",
      "10:00 --- @NUM[1000.0]\n",
      "37900.00 --- @NUM[37900.0]\n",
      "9.65% --- @NUM[9.65] percent\n",
      "$40,550 --- @NUM[40550.0] dollar\n",
      "2021-2025 --- 2021 2025\n",
      "1.001374 --- @NUM[1001374.0]\n",
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21677 | Known words: 8606\n",
      "+5.58% --- @NUM[5.58] percent\n",
      "-5.41% --- @NUM[-5.41] percent\n",
      "1,500 --- @NUM[1500.0]\n",
      "24-hour --- 24 hour\n",
      "10:00 --- @NUM[1000.0]\n",
      "37900.00 --- @NUM[37900.0]\n",
      "9.65% --- @NUM[9.65] percent\n",
      "$40,550 --- @NUM[40550.0] dollar\n",
      "2021-2025 --- 2021 2025\n",
      "1.001374 --- @NUM[1001374.0]\n",
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21677 | Known words: 8606\n",
      "+5.58% --- @NUM[5.58] percent\n",
      "-5.41% --- @NUM[-5.41] percent\n",
      "1,500 --- @NUM[1500.0]\n",
      "24-hour --- 24 hour\n",
      "10:00 --- @NUM[1000.0]\n",
      "37900.00 --- @NUM[37900.0]\n",
      "9.65% --- @NUM[9.65] percent\n",
      "$40,550 --- @NUM[40550.0] dollar\n",
      "2021-2025 --- 2021 2025\n",
      "1.001374 --- @NUM[1001374.0]\n",
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21677 | Known words: 8606\n",
      "+5.58% --- @NUM[5.58] percent\n",
      "-5.41% --- @NUM[-5.41] percent\n",
      "1,500 --- @NUM[1500.0]\n",
      "24-hour --- 24 hour\n",
      "10:00 --- @NUM[1000.0]\n",
      "37900.00 --- @NUM[37900.0]\n",
      "9.65% --- @NUM[9.65] percent\n",
      "$40,550 --- @NUM[40550.0] dollar\n",
      "2021-2025 --- 2021 2025\n",
      "1.001374 --- @NUM[1001374.0]\n"
     ]
    }
   ],
   "source": [
    "scale_mapping = {\n",
    "    'b': 1000000000,\n",
    "    'bn': 1000000000,\n",
    "    'bln': 1000000000,\n",
    "    'billion': 1000000000,\n",
    "    'm': 1000000,\n",
    "    'mn': 1000000,\n",
    "    'mln': 1000000,\n",
    "    'million': 1000000,\n",
    "    'k': 1000,\n",
    "    'thousand': 1000,\n",
    "    '-': -1,\n",
    "}\n",
    "\n",
    "translate = {\n",
    "    '$': 'dollar', 'Â£': 'pound','%': 'percent', 'â‚¬': 'euro'\n",
    "}\n",
    "\n",
    "translate_suffix = {\n",
    "    'x': 'times'\n",
    "}\n",
    "\n",
    "translate_prefix = {\n",
    "    '~': 'around',\n",
    "    '+-': 'around',\n",
    "    'Â±': 'around',\n",
    "    '@': 'at',\n",
    "    '=': 'equals',\n",
    "    '*#': 'ranked',\n",
    "    '#': 'ranked',\n",
    "}\n",
    "\n",
    "def serialize_numbers(texts):\n",
    "    temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "    temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "    temp_dict = {}\n",
    "    re_inb = re.compile('[,\\'\"`]')\n",
    "    re_num = re.compile('^(~|\\+-|Â±|@|=|#|\\*#)?[-@+*^#:]?[$Â£%â‚¬]?(([.:]?[0-9])+)[$Â£%â‚¬]?')\n",
    "    re_fix = re.compile('^[$Â£%â‚¬][-+][0-9]')\n",
    "    for word in temp_vocab:\n",
    "        prefilter = re_inb.sub('', word).replace(',', '.')\n",
    "        if re_fix.search(prefilter):\n",
    "            prefilter = prefilter[1] + prefilter[0] + prefilter[2:]\n",
    "        result = re_num.search(prefilter)\n",
    "\n",
    "        if result and result.pos == 0:\n",
    "            # Process combined numbers / ranges in next iteration\n",
    "            if '-' in word and not word.startswith('-') and not word.startswith('+-'):\n",
    "                temp_dict[word] = ' '.join(word.split('-'))\n",
    "                continue\n",
    "\n",
    "            main_part = prefilter[:result.end()]\n",
    "            prefix = ''\n",
    "            for prefix_key, prefix_name in translate_prefix.items():\n",
    "                if main_part.startswith(prefix_key):\n",
    "                    prefix = prefix_name\n",
    "                    main_part = main_part.replace(prefix_key, '', 1)\n",
    "                    break\n",
    "\n",
    "            main = re.compile('^[~@+*^#:]').sub('',main_part)\n",
    "            currency = re.compile('[$Â£%â‚¬]').search(main)\n",
    "            currency = main[currency.start():currency.end()] if currency else None\n",
    "            main = re.compile('[$Â£%â‚¬]').sub('', main)\n",
    "            suffix = prefilter[result.end():]\n",
    "\n",
    "            multiplier = 1\n",
    "            if re.compile('\\.[0-9]{1,2}$').search(main): # decimal\n",
    "                multiplier *= 0.01 if main[-1].isnumeric() else 0.1\n",
    "            if '-' in main: # Neg numbers\n",
    "                multiplier *= -1\n",
    "                main = main.replace('-', '')\n",
    "            # Textual scale\n",
    "            if suffix in scale_mapping:\n",
    "                multiplier *= scale_mapping[suffix]\n",
    "                suffix = ''\n",
    "            if suffix in translate_suffix:\n",
    "                suffix = translate_suffix[suffix]\n",
    "\n",
    "            number = round(float(main.replace('.', '').replace(':', '')) * multiplier, 2)\n",
    "            # print(f'{number}  /  {currency}  /  {suffix}  /  {word}')\n",
    "            # noinspection PyTypeChecker\n",
    "            temp_dict[word] = ' '.join(filter(len,[\n",
    "                prefix,\n",
    "                place_hold(str(number), NUMBER_TAG),\n",
    "                translate[currency] if currency else '',\n",
    "                suffix\n",
    "            ]))\n",
    "\n",
    "    texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "    if verbose: print('#' * 10, 'Step - Serialize numbers:'); check_vocab(texts, local_vocab);\n",
    "    if verbose: print_dict(temp_dict)\n",
    "    return texts\n",
    "\n",
    "\n",
    "# Clean up numbers\n",
    "for i in range(4):\n",
    "    texts.pipe(serialize_numbers)\n",
    "    # texts = texts.pipe(serialize_numbers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 21200 | Known words: 8606\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 21037 | Known words: 8606\n",
      "$usdt --- @CURR[usdt]\n",
      "$usd --- @CURR[usd]\n",
      "$aapl --- @CURR[aapl]\n",
      "$hai --- @CURR[hai]\n",
      "$bch --- @CURR[bch]\n",
      "$strax --- @CURR[strax]\n",
      "$riot --- @CURR[riot]\n",
      "#cryptocurrencies --- @HTAG[cryptocurrencies]\n",
      "$comp --- @CURR[comp]\n",
      "$arbkf --- @CURR[arbkf]\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "@HTAG[elt] --- @CURR[elt]\n",
      "@HTAG[crypto] --- @CURR[crypto]\n",
      "@HTAG[batman] --- @CURR[batman]\n",
      "@HTAG[tezos] --- @CURR[tezos]\n",
      "@USR[tezos] --- @CURR[tezos]\n",
      "@HTAG[fma] --- @CURR[fma]\n",
      "@HTAG[defi] --- @CURR[defi]\n",
      "@HTAG[bitcoin] --- @CURR[bitcoin]\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Start word punctuations:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "'science --- ' science\n",
      "*telegram --- * telegram\n",
      ".could --- . could\n",
      "*police --- * police\n",
      "-it --- - it\n",
      "*q --- * q\n",
      ".you --- . you\n",
      "\\4241491.0 --- \\ 4241491.0\n",
      "~the --- ~ the\n",
      "Â£5 --- Â£ 5\n"
     ]
    }
   ],
   "source": [
    "# Start word punctuations\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and (not k[0].isalnum() and k[0] not in ['@', '#', '$'])]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = word\n",
    "    for i in range(len(word)):\n",
    "        if word[i].isalnum() or word[i] in ['#', '@', '$']:\n",
    "            new_word = word[:i] + ' ' + word[i:]\n",
    "            break\n",
    "    temp_dict[word] = new_word\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "# texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Start word punctuations:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 21029 | Known words: 8606\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Find and replace acronims:\n",
      "Unknown words: 21029 | Known words: 8606\n",
      "g.o.a.t --- word_placeholder[goat]\n",
      "p.o.d --- word_placeholder[pod]\n",
      "f.i.a.t --- word_placeholder[fiat]\n"
     ]
    }
   ],
   "source": [
    "# Find and replace acronims\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if (Counter(word)['.']>1) and (check_replace(word)):\n",
    "        if (domain_search(word)!='') and (('www' in word) or (Counter(word)['/']>3)):\n",
    "            temp_dict[word] = place_hold('url ' + domain_search(word))\n",
    "        else:\n",
    "            if (re.compile('[\\.\\,]').sub('', word) in local_vocab) and (len(re.compile('[0-9\\.\\,\\-\\/\\:]').sub('', word))>0):\n",
    "                temp_dict[word] =  place_hold(re.compile('[\\.\\,]').sub('', word))\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Find and replace acronims:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Contractions:\n",
      "Unknown words: 20967 | Known words: 8606\n",
      "i'd --- i would\n",
      "this's --- this is\n",
      "he's --- he is\n",
      "shouldn't --- should not\n",
      "ya'll --- you will\n",
      "can't --- cannot\n",
      "when's --- when is\n",
      "who's --- who is\n",
      "you've --- you have\n",
      "they're --- they are\n"
     ]
    }
   ],
   "source": [
    "# Apply spellchecker for contractions\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and (\"'\" in k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if word in helper_contractions:\n",
    "        temp_dict[word] = helper_contractions[word] # place_hold(helper_contractions[word])\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Contractions:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Remove \"s:\n",
      "Unknown words: 20745 | Known words: 8617\n",
      "c's --- c\n",
      "sucker's --- sucker\n",
      "satoshi's --- satoshi\n",
      "#ether's --- #ether\n",
      "greeneum's --- greeneum\n",
      "case's --- case\n",
      "@microstrategy's --- @microstrategy\n",
      "robinhood's --- robinhood\n",
      "quantum's --- quantum\n",
      "bridgewater's --- bridgewater\n"
     ]
    }
   ],
   "source": [
    "# Remove 's (DO WE NEED TO REMOVE IT???)\n",
    "# Local\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {k:k[:-2] for k in temp_vocab if (check_replace(k)) and (k.lower()[-2:]==\"'s\")}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Remove \"s:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Convert backslash:\n",
      "Unknown words: 20745 | Known words: 8617\n",
      "\\4241491.0 ---  / 4241491.0\n",
      "\\4301056.0 ---  / 4301056.0\n",
      "\\5058389.0 ---  / 5058389.0\n",
      "\\4299147.0 ---  / 4299147.0\n",
      "\\4233436.0 ---  / 4233436.0\n",
      "\\4238285.0 ---  / 4238285.0\n",
      "\\4240291.0 ---  / 4240291.0\n"
     ]
    }
   ],
   "source": [
    "# Convert backslash\n",
    "# Global\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and ('\\\\' in k)]\n",
    "temp_dict = {k:re.sub('\\\\\\\\+', ' / ', k) for k in temp_vocab}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Convert backslash:'); check_vocab(texts, local_vocab)\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 20745 | Known words: 8617\n",
      "5058389.0 --- @NUM[50583890.0]\n",
      "4301056.0 --- @NUM[43010560.0]\n",
      "4240291.0 --- @NUM[42402910.0]\n",
      "4238285.0 --- @NUM[42382850.0]\n",
      "4233436.0 --- @NUM[42334360.0]\n",
      "4299147.0 --- @NUM[42991470.0]\n",
      "4241491.0 --- @NUM[42414910.0]\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 20738 | Known words: 8617\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 20702 | Known words: 8617\n",
      "#telcoin --- @HTAG[telcoin]\n",
      "#cryptocurrencies --- @HTAG[cryptocurrencies]\n",
      "#nyzo --- @HTAG[nyzo]\n",
      "@iohk_charles --- @USR[iohk_charles]\n",
      "@thedaomaker --- @USR[thedaomaker]\n",
      "#cryptocurrency --- @HTAG[cryptocurrency]\n",
      "@petermccormack --- @USR[petermccormack]\n",
      "@cointelegraph --- @USR[cointelegraph]\n",
      "$doge --- @CURR[doge]\n",
      "#silver --- @HTAG[silver]\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 20688 | Known words: 8617\n",
      "@USR[dogecoin] --- @CURR[dogecoin]\n",
      "@USR[sylo] --- @CURR[sylo]\n",
      "@HTAG[crypto] --- @CURR[crypto]\n",
      "@HTAG[tesla] --- @CURR[tesla]\n",
      "@USR[tesla] --- @CURR[tesla]\n",
      "@USR[sofi] --- @CURR[sofi]\n",
      "@HTAG[ether] --- @CURR[ether]\n",
      "@HTAG[cme] --- @CURR[cme]\n",
      "@HTAG[nyzo] --- @CURR[nyzo]\n",
      "@USR[paypal] --- @CURR[paypal]\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Dup chars (with vocab check):\n",
      "Unknown words: 20436 | Known words: 8654\n",
      "niine --- nine\n",
      "ayyyyyeeeee --- aye\n",
      "thousaaaaaand --- thousand\n",
      "canvass --- canvas\n",
      "ooh --- oh\n",
      "bounceeeee --- bounce\n",
      "brrr --- br\n",
      "yeahhh --- yeah\n",
      "richhh --- rich\n",
      "untill --- until\n"
     ]
    }
   ],
   "source": [
    "# Try remove duplicated chars (not sure about this!!!!!). TODO check fist against vocab?\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "\n",
    "temp_dict = {}\n",
    "temp_vocab_dup = []\n",
    "\n",
    "for word in temp_vocab:\n",
    "    if not word.isalpha():\n",
    "        continue\n",
    "    temp_vocab_dup.append(''.join(ch for ch, _ in itertools.groupby(word)))\n",
    "temp_vocab_dup = set(temp_vocab_dup)\n",
    "temp_vocab_dup = temp_vocab_dup.difference(temp_vocab_dup.difference(set(local_vocab)))\n",
    "\n",
    "for word in temp_vocab:\n",
    "    new_word = ''.join(ch for ch, _ in itertools.groupby(word))\n",
    "    if new_word in temp_vocab_dup:\n",
    "        temp_dict[word] = new_word\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if (k != v) and (v in local_vocab)}\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Dup chars (with vocab check):'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 20436 | Known words: 8654\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 20436 | Known words: 8654\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 20436 | Known words: 8654\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 20436 | Known words: 8654\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Isolate numbers:\n",
      "Unknown words: 20436 | Known words: 8654\n",
      ":-6.11 --- word_placeholder[:-6.11]\n",
      "*_100% --- word_placeholder[*_100%]\n"
     ]
    }
   ],
   "source": [
    "# Isolate numbers\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if re.compile('[a-zA-Z]').sub('', word) == word:\n",
    "        if re.compile('[0-9]').sub('', word) != word:\n",
    "            temp_dict[word] = word\n",
    "\n",
    "global_chars_list = list(set([c for line in temp_dict for c in line]))\n",
    "chars = ''.join([c for c in global_chars_list if not c.isdigit()])\n",
    "chars_dict = {ord(c):f' {c} ' for c in chars}\n",
    "temp_dict = {k:place_hold(k) for k in temp_dict}\n",
    "\n",
    "#texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Isolate numbers:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Join dashes:\n",
      "Unknown words: 20430 | Known words: 8654\n",
      "clockwork--up --- clockwork-up\n",
      "--designed --- -designed\n",
      "outshined--cryptocurrency --- outshined-cryptocurrency\n",
      "----- --- -\n",
      "------------- --- -\n",
      "#crypto!--where --- #crypto!-where\n",
      "--- --- -\n",
      "-- --- -\n",
      "aa--tag --- aa-tag\n",
      "------------------------------------------ --- -\n"
     ]
    }
   ],
   "source": [
    "# Join dashes\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    temp_dict[word] = re.sub('\\-\\-+', '-', word)\n",
    "temp_dict = {k: v for k, v in temp_dict.items() if k != v}\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Join dashes:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Try Split word:\n",
      "Unknown words: 20430 | Known words: 8654\n"
     ]
    }
   ],
   "source": [
    "# Try join word (Sloooow)\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (check_replace(k)) and (Counter(k)['-']>1)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = ''.join(['' if c in '-' else c for c in word])\n",
    "    if (new_word in local_vocab) and (len(new_word)>3):\n",
    "        temp_dict[word] = new_word\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Try Split word:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Try Split word:\n",
      "Unknown words: 19331 | Known words: 8753\n",
      "price:0.0000000019 --- price : 0 . 0000000019\n",
      "'science ---  ' science\n",
      "solidity-based --- solidity - based\n",
      "geo-location --- geo - location\n",
      "##btc ---  #  # btc\n",
      "ðŸ§¡ ---  ðŸ§¡ \n",
      "ðŸš‚ ---  ðŸš‚ \n",
      "ðŸ– ---  ðŸ– \n",
      "target:47716.95 --- target : 47716 . 95\n",
      "ðŸ’Œ ---  ðŸ’Œ \n"
     ]
    }
   ],
   "source": [
    "# Try Split word\n",
    "# Local (only unknown words)\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    if len(re.compile('[a-zA-Z0-9\\*]').sub('', word))>0:\n",
    "        chars = re.compile('[a-zA-Z0-9\\*]').sub('', word)\n",
    "        temp_dict[word] = ''.join([' ' + c + ' ' if c in chars else c for c in word])\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Try Split word:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - L33T (with vocab check):\n",
      "Unknown words: 19327 | Known words: 8756\n",
      "t13 --- tie\n",
      "or3 --- ore\n",
      "sh1t --- shit\n",
      "fa1 --- fai\n"
     ]
    }
   ],
   "source": [
    "# L33T vocabulary (SLOW)\n",
    "# https://simple.wikipedia.org/wiki/Leet\n",
    "# Local (only unknown words)\n",
    "def convert_leet(word):\n",
    "    # basic conversion\n",
    "    word = re.sub('0', 'o', word)\n",
    "    word = re.sub('1', 'i', word)\n",
    "    word = re.sub('3', 'e', word)\n",
    "    word = re.sub('\\$', 's', word)\n",
    "    word = re.sub('\\@', 'a', word)\n",
    "    return word\n",
    "\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if check_replace(k)]\n",
    "\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    new_word = convert_leet(word)\n",
    "    if (new_word!=word):\n",
    "        if (len(word)>2) and (new_word in local_vocab):\n",
    "            temp_dict[word] = new_word\n",
    "\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - L33T (with vocab check):'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 19298 | Known words: 8757\n",
      "588 --- @NUM[588.0]\n",
      "43000 --- @NUM[43000.0]\n",
      "2511 --- @NUM[2511.0]\n",
      "012736 --- @NUM[12736.0]\n",
      "47716 --- @NUM[47716.0]\n",
      "2421 --- @NUM[2421.0]\n",
      "2272 --- @NUM[2272.0]\n",
      "078 --- @NUM[78.0]\n",
      "07059741519 --- @NUM[7059741519.0]\n",
      "047 --- @NUM[47.0]\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 19294 | Known words: 8757\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 19283 | Known words: 8757\n",
      "@bitstamp --- @USR[bitstamp]\n",
      "#cryptocurrencies --- @HTAG[cryptocurrencies]\n",
      "$doge --- @CURR[doge]\n",
      "$trx --- @CURR[trx]\n",
      "@binance --- @USR[binance]\n",
      "$btc --- @CURR[btc]\n",
      "#altcoins --- @HTAG[altcoins]\n",
      "$eth --- @CURR[eth]\n",
      "#hodl --- @HTAG[hodl]\n",
      "#crypto --- @HTAG[crypto]\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 19282 | Known words: 8757\n",
      "@HTAG[crypto] --- @CURR[crypto]\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Open Holded words:\n",
      "Unknown words: 19279 | Known words: 8759\n"
     ]
    }
   ],
   "source": [
    "# Remove placeholders\n",
    "# Global\n",
    "temp_vocab = list(set([c for line in texts for c in line.split()]))\n",
    "temp_vocab = [k for k in temp_vocab if (not check_replace(k) and k.startswith(WPLACEHOLDER))]\n",
    "temp_dict = {}\n",
    "for word in temp_vocab:\n",
    "    temp_dict[word] = re.sub('___', ' ', word[17:-1])\n",
    "texts = texts.apply(lambda x: ' '.join([temp_dict.get(i, i) for i in x.split()]))\n",
    "texts = texts.apply(lambda x: ' '.join([i for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Open Holded words:'); check_vocab(texts, local_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Multiple form:\n",
      "Unknown words: 18977 | Known words: 8832\n",
      "feedbacks --- feedback\n",
      "coincides --- coincide\n",
      "declarations --- declaration\n",
      "panics --- panic\n",
      "repays --- repay\n",
      "showdowns --- showdown\n",
      "informations --- information\n",
      "evolves --- evolve\n",
      "harvests --- harvest\n",
      "anyways --- anyway\n"
     ]
    }
   ],
   "source": [
    "# Search multiple form\n",
    "# Local | example -> flashlights / flashlight -> False / True\n",
    "temp_vocab = check_vocab(texts, local_vocab, response='unknown_list')\n",
    "temp_vocab = [k for k in temp_vocab if (k[-1:]=='s') and (len(k)>4)]\n",
    "temp_dict = {k:k[:-1] for k in temp_vocab if (k[:-1] in local_vocab)}\n",
    "texts = texts.apply(lambda x: ' '.join([make_dict_cleaning(i,temp_dict) for i in x.split()]))\n",
    "if verbose: print('#' * 10, 'Step - Multiple form:'); check_vocab(texts, local_vocab);\n",
    "if verbose: print_dict(temp_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Step - Serialize numbers:\n",
      "Unknown words: 18977 | Known words: 8832\n",
      "########## Step - Custom word synonyms:\n",
      "Unknown words: 18977 | Known words: 8832\n",
      "#btc --- #bitcoin\n",
      "btc --- $btc\n",
      "bitcoins --- $btc\n",
      "bitcoin --- $btc\n",
      "@bitcoin --- $btc\n",
      "#crypto --- #cryptocurrency\n",
      "#eth --- $eth\n",
      "ethereum --- $eth\n",
      "eth --- $eth\n",
      "#bch --- $bch\n",
      "########## Step - UserName and Hashtag:\n",
      "Unknown words: 18977 | Known words: 8832\n",
      "########## Step - Hashtag and currency union:\n",
      "Unknown words: 18977 | Known words: 8832\n"
     ]
    }
   ],
   "source": [
    "# Extract entities again and numbers\n",
    "texts = texts.pipe(serialize_numbers)\n",
    "texts = texts\\\n",
    "    .pipe(custom_synonyms)\\\n",
    "    .pipe(extract_entities)\\\n",
    "    .pipe(hashtag_currency_union)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: 0.03805000000000003\n",
      "########## Step - Language datection:\n",
      "Unknown words: 17403 | Known words: 8681\n"
     ]
    }
   ],
   "source": [
    "# Cut away non english tweets\n",
    "model = fasttext.load_model('../../data/kaggle/lid.176.ftz')\n",
    "\n",
    "def langcheck(item, min_confidence=0.2):\n",
    "    text = ' '.join([w for w in item.split() if not w.startswith('@')])\n",
    "    if len(text) < 3:\n",
    "        return True\n",
    "    results = dict(zip(*model.predict(text, k=2)))\n",
    "    return results.get('__label__en', 0) > min_confidence\n",
    "\n",
    "mask = texts.parallel_map(langcheck)\n",
    "if verbose: print(f'Deleted: {1 - sum(mask)/len(texts)}')\n",
    "texts = texts[mask]\n",
    "data = data[mask]\n",
    "if verbose: print('#' * 10, 'Step - Language datection:'); check_vocab(texts, local_vocab);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                       _id  \\\n0      1360142875330232324   \n1      1360140112861003776   \n2      1360137307047694337   \n4      1360132401142366210   \n5      1360131434158170113   \n...                    ...   \n19995  1357792968455946242   \n19996  1357792933982928896   \n19997  1357792930359107588   \n19998  1357792864005095424   \n19999  1357792837870510083   \n\n                                                                                                                                                                                                          text  \n0      when the top u . s . central banker gets photobombed by @CURR[btc] . ðŸ‘‰ ðŸ‘€ @CURR[bitcoin] @CURR[bitcoin] @HTAG[cryptocurrency] @HTAG[cryptocurrency] @HTAG[ethereum] @HTAG[ripple] @CURR[link] @HTAG[c...  \n1      best am arriving with exciting features @CURR[bsc] @USR[binance] @CURR[bitcoin] @HTAG[binancesmartchain] @CURR[defi] @HTAG[definews] @HTAG[stafi] @CURR[cake] @HTAG[pancakeswap] @HTAG[paraswap] @HT...  \n2      to keep its ultra bullish run intact , @CURR[egld] bulls need to keep @CURR[egld] / @CURR[usdt] daily above @NUM[148.0] dollar . reclaiming @NUM[174.0] dollar would be superb . break @NUM[148.0] d...  \n4      next coin that goes @NUM[100.0] percent . . . buckle up . . . @CURR[xtz] @CURR[xtz] @CURR[tezos] look @ my calls from last 2 weeks @CURR[iota] @CURR[coti] tezos will move hard incoming days . @CUR...  \n5                        its gonna be huge ! ðŸš€ ðŸ˜ ðŸ‘‘ @HTAG[fetch_ai] ðŸ‘‘ @CURR[xrp] @HTAG[vechain] @HTAG[chainlink] @HTAG[cardano] @HTAG[algorand] @HTAG[altcoins] @HTAG[artificialintelligence] @HTAG[blockchain]  \n...                                                                                                                                                                                                        ...  \n19995                                                                                                                                                                             cash is trash @CURR[bitcoin]  \n19996                                                                                               global central bank efforts to limit u . s . dollars decline raises specter of currency war @CURR[bitcoin]  \n19997                                                                                                                                       what if @CURR[bitcoin] is a social experiment ? well , money was .  \n19998                                                                                                       @CURR[bitcoin] btw that was pre close ny - cme friday dump . pl are closing positions b4 weekend .  \n19999                                                                                                                                           nigeria is fucked and pregnant with stupidity . @CURR[bitcoin]  \n\n[19239 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1360142875330232324</td>\n      <td>when the top u . s . central banker gets photobombed by @CURR[btc] . ðŸ‘‰ ðŸ‘€ @CURR[bitcoin] @CURR[bitcoin] @HTAG[cryptocurrency] @HTAG[cryptocurrency] @HTAG[ethereum] @HTAG[ripple] @CURR[link] @HTAG[c...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1360140112861003776</td>\n      <td>best am arriving with exciting features @CURR[bsc] @USR[binance] @CURR[bitcoin] @HTAG[binancesmartchain] @CURR[defi] @HTAG[definews] @HTAG[stafi] @CURR[cake] @HTAG[pancakeswap] @HTAG[paraswap] @HT...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1360137307047694337</td>\n      <td>to keep its ultra bullish run intact , @CURR[egld] bulls need to keep @CURR[egld] / @CURR[usdt] daily above @NUM[148.0] dollar . reclaiming @NUM[174.0] dollar would be superb . break @NUM[148.0] d...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1360132401142366210</td>\n      <td>next coin that goes @NUM[100.0] percent . . . buckle up . . . @CURR[xtz] @CURR[xtz] @CURR[tezos] look @ my calls from last 2 weeks @CURR[iota] @CURR[coti] tezos will move hard incoming days . @CUR...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1360131434158170113</td>\n      <td>its gonna be huge ! ðŸš€ ðŸ˜ ðŸ‘‘ @HTAG[fetch_ai] ðŸ‘‘ @CURR[xrp] @HTAG[vechain] @HTAG[chainlink] @HTAG[cardano] @HTAG[algorand] @HTAG[altcoins] @HTAG[artificialintelligence] @HTAG[blockchain]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>1357792968455946242</td>\n      <td>cash is trash @CURR[bitcoin]</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>1357792933982928896</td>\n      <td>global central bank efforts to limit u . s . dollars decline raises specter of currency war @CURR[bitcoin]</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>1357792930359107588</td>\n      <td>what if @CURR[bitcoin] is a social experiment ? well , money was .</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>1357792864005095424</td>\n      <td>@CURR[bitcoin] btw that was pre close ny - cme friday dump . pl are closing positions b4 weekend .</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>1357792837870510083</td>\n      <td>nigeria is fucked and pregnant with stupidity . @CURR[bitcoin]</td>\n    </tr>\n  </tbody>\n</table>\n<p>19239 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = texts\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TODO:\n",
    "* numbers\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}